{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "authorship_tag": "ABX9TyMa58FWjh7N51J9/5y9+Bks"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "OKdr0AFPWE7x"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# íŒŒì¥ ì •ì˜\n",
        "WAVELENGTHS = np.arange(380, 781, 1)\n",
        "NUM_WAVELENGTHS = len(WAVELENGTHS) #401\n",
        "\n",
        "# GitHub raw ì£¼ì†Œ (íŒŒì¼ë“¤ì´ ìœ„ì¹˜í•œ ê²½ë¡œ)\n",
        "base_url = \"https://raw.githubusercontent.com/KIMEUIJOON-KNU/Bi-directional/main/\"\n",
        "\n",
        "# ì‚¬ìš©í•  ì¬ë£Œ ëª©ë¡\n",
        "material_files = [\n",
        "    ('SiO2', 'SiO2_380.csv'),\n",
        "    ('WO3',  'WO3_380.csv'),\n",
        "    ('Ag',   'Ag_380.csv')\n",
        "]\n",
        "\n",
        "material_data = {}\n",
        "material_names = [info[0] for info in material_files]\n",
        "print(\"ì¬ë£Œ ë¦¬ìŠ¤íŠ¸:\", material_names)\n",
        "\n",
        "# ì¬ë£Œ ì¸ë±ì‹± ë§¤í•‘\n",
        "material_names = sorted(set(material_names))\n",
        "material_to_index = {name: i for i, name in enumerate(material_names)}\n",
        "index_to_material = {i: name for name, i in material_to_index.items()}\n",
        "print(\"ì¬ë£Œ ì¸ë±ìŠ¤ ë§¤í•‘:\", index_to_material)\n",
        "\n",
        "# --- ì¬ë£Œ íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸° ---\n",
        "for material_name, filename in material_files:\n",
        "    file_url = base_url + filename\n",
        "    print(f\"ì²˜ë¦¬ ì¤‘: {filename} (materials: {material_name}) â†’ {file_url}\")\n",
        "    try:\n",
        "        data = pd.read_csv(file_url, header=None)\n",
        "    except Exception as e:\n",
        "        print(f\"  ğŸš« ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
        "        continue\n",
        "\n",
        "    if data.empty:\n",
        "        print(\"  âš ï¸ ê²½ê³ : íŒŒì¼ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.\")\n",
        "        continue\n",
        "\n",
        "    wavelengths = data.iloc[:, 0].values  # íŒŒì¥\n",
        "    n = data.iloc[:, 1].values           # ì‹¤ìˆ˜ë¶€\n",
        "    k = data.iloc[:, 2].values           # í—ˆìˆ˜ë¶€\n",
        "\n",
        "    n_complex = n + 1j * k               # ë³µì†Œ êµ´ì ˆë¥ \n",
        "\n",
        "    material_data[material_name] = (wavelengths, n_complex)\n",
        "    print(f\"ë¡œë“œ ì™„ë£Œ: {len(wavelengths)} points\")\n",
        "\n",
        "# --- ê³µê¸° êµ´ì ˆë¥  ì¶”ê°€ ---\n",
        "material_data['Air'] = np.ones(NUM_WAVELENGTHS, dtype=np.complex128)\n",
        "print(\"Air êµ´ì ˆë¥  ì¶”ê°€ ì™„ë£Œ\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6wcpY_qWA9B",
        "outputId": "8eef385a-23fa-4c16-9f8a-7fe6e09ad575"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ì¬ë£Œ ë¦¬ìŠ¤íŠ¸: ['SiO2', 'WO3', 'Ag']\n",
            "ì¬ë£Œ ì¸ë±ìŠ¤ ë§¤í•‘: {0: 'Ag', 1: 'SiO2', 2: 'WO3'}\n",
            "ì²˜ë¦¬ ì¤‘: SiO2_380.csv (materials: SiO2) â†’ https://raw.githubusercontent.com/KIMEUIJOON-KNU/Bi-directional/main/SiO2_380.csv\n",
            "ë¡œë“œ ì™„ë£Œ: 401 points\n",
            "ì²˜ë¦¬ ì¤‘: WO3_380.csv (materials: WO3) â†’ https://raw.githubusercontent.com/KIMEUIJOON-KNU/Bi-directional/main/WO3_380.csv\n",
            "ë¡œë“œ ì™„ë£Œ: 401 points\n",
            "ì²˜ë¦¬ ì¤‘: Ag_380.csv (materials: Ag) â†’ https://raw.githubusercontent.com/KIMEUIJOON-KNU/Bi-directional/main/Ag_380.csv\n",
            "ë¡œë“œ ì™„ë£Œ: 401 points\n",
            "Air êµ´ì ˆë¥  ì¶”ê°€ ì™„ë£Œ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# (1) íŒŒì¥ ì •ì˜ (380~780 nm, 1 nm ê°„ê²© â†’ ì´ 401ê°œ íŒŒì¥ ì§€ì )\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "Î»_tensor_global = torch.tensor(WAVELENGTHS, dtype=torch.float64).to(device) * 1e-9  # [m ë‹¨ìœ„ë¡œ ë³€í™˜ëœ íŒŒì¥ í…ì„œ]\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# (2) ì¸µë³„ ì¬ë£Œ ì •ì˜ (MIM êµ¬ì¡° ì˜ˆì‹œ: ê¸ˆì†-ì ˆì—°ì²´-ê¸ˆì†)\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "material_sequence = ['Ag', 'WO3', 'Ag']  # êµ¬ì¡°ì— ì‚¬ìš©ë  ì¬ë£Œ ìˆœì„œ (ì…ì‚¬ë©´ì—ì„œë¶€í„° ì•„ë˜ ë°©í–¥)\n",
        "\n",
        "# material_data ì—ì„œ ê° ì¬ë£Œì˜ ë³µì†Œ êµ´ì ˆë¥  (n + ik) ê°’ ì¶”ì¶œ (shape: [401])\n",
        "n_list_np_arrays = [material_data[mat][1] for mat in material_sequence]  # ê¸¸ì´ 3 ë¦¬ìŠ¤íŠ¸ (ê°ê° [401] í¬ê¸°)\n",
        "\n",
        "# numpy â†’ torch ë³€í™˜ í›„, complex64 í˜•ì‹ìœ¼ë¡œ ë¬¶ì–´ì„œ GPUë¡œ ì´ë™ (shape: [3, 401])\n",
        "n_list_torch = torch.stack([\n",
        "    torch.from_numpy(arr).to(torch.complex64) for arr in n_list_np_arrays\n",
        "], dim=0).to(device)\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# (3) ì…ì‚¬ ë§¤ì§ˆ (n_i)ì™€ ì¶œì‚¬ ë§¤ì§ˆ (n_s) ì„¤ì •\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "n_i_np = material_data['SiO2'][1]   # ì…ì‚¬ ë§¤ì§ˆ: SiO2ì˜ ë³µì†Œ êµ´ì ˆë¥  (n + ik)\n",
        "n_s_np = material_data['Air']       # ì¶œì‚¬ ë§¤ì§ˆ: Air (n=1, k=0)\n",
        "\n",
        "n_i_torch = torch.from_numpy(n_i_np).to(torch.complex64).to(device)  # torch ë³€í™˜ í›„ GPU ì´ë™\n",
        "n_s_torch = torch.from_numpy(n_s_np).to(torch.complex64).to(device)\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# (4) ë‘ê»˜ ê·¸ë¦¬ë“œ ì •ì˜ (nm ë‹¨ìœ„, ì´ ì¡°í•© ìˆ˜ = 8 * 187 * 8 = 11968ê°œ)\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "d1_list_nm = np.arange(5, 41, 5)      # ê¸ˆì†ì¸µ (d1): 5 ~ 40 nm, ê°„ê²© 5 nm â†’ ì´ 8ê°œ\n",
        "d2_list_nm = np.arange(150, 801, 5)    # ì ˆì—°ì¸µ (d2): 20 ~ 950 nm, ê°„ê²© 5 nm â†’ ì´ 187ê°œ\n",
        "d3_list_nm = np.arange(5, 41, 5)      # ê¸ˆì†ì¸µ (d3): 5 ~ 40 nm, ê°„ê²© 5 nm â†’ ì´ 8ê°œ\n",
        "\n",
        "print(len(d1_list_nm)*len(d2_list_nm)*len(d3_list_nm))  # ì´ ì¡°í•© ê°œìˆ˜ ì¶œë ¥ (8 Ã— 187 Ã— 8 = 11,968)\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# (5) ìƒ˜í”Œ ì €ì¥ìš© ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "all_d_tilde = []    # â–¶ ê° ìƒ˜í”Œì˜ (d1, d2, d3) ë‘ê»˜ ì¡°í•©ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸\n",
        "                    #   ì¼ë°˜ì ìœ¼ë¡œ ë‚˜ì¤‘ì— ì •ê·œí™”ëœ í˜•íƒœë¡œ ì €ì¥ë˜ë©° í•™ìŠµ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©\n",
        "\n",
        "all_T_target = []   # â–¶ ê° ì¡°í•©ì— ëŒ€ì‘í•˜ëŠ” ìŠ¤í™íŠ¸ëŸ¼ T(Î») [shape: (401,)] ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸\n",
        "                    #   Forward modelì„ í†µí•´ ê³„ì‚°ëœ ì •ë‹µ ìŠ¤í™íŠ¸ëŸ¼ (target)\n"
      ],
      "metadata": {
        "id": "qKoHAdIqxvHg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bd87892-03d5-466f-8d66-9a299cc8431f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8384\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# (A-1) TMMNetwork ì •ì˜ (í´ë˜ìŠ¤ ì´ë¦„, dtype í†µì¼, calculate() ì¶”ê°€)\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "class TMMNetwork(nn.Module):\n",
        "    def __init__(self, n_list_input, n_i_input, n_s_input, wavelengths_m_tensor):\n",
        "        super().__init__()\n",
        "        dtype_complex = torch.complex128\n",
        "        dtype_float = torch.float64\n",
        "\n",
        "        n_list_real = n_list_input.real\n",
        "        n_list_imag = -torch.abs(n_list_input.imag)\n",
        "        self.register_buffer('n_list', torch.complex(n_list_real, n_list_imag))\n",
        "        self.register_buffer('n_i', n_i_input.to(dtype_complex))\n",
        "        self.register_buffer('n_s', n_s_input.to(dtype_complex))\n",
        "\n",
        "        # íŒŒìˆ˜ k0\n",
        "        k0 = 2 * torch.pi / torch.clamp(wavelengths_m_tensor, min=1e-20)\n",
        "        self.register_buffer('k0', k0)  # ì´ì œ k0_tilde ì•„ë‹˜\n",
        "\n",
        "        self.num_layers = self.n_list.shape[0]\n",
        "        self.num_wavelengths = wavelengths_m_tensor.shape[0]\n",
        "\n",
        "    def forward(self, thicknesses_nm):\n",
        "        device = thicknesses_nm.device\n",
        "        dtype_complex = torch.complex128\n",
        "        imag_unit = torch.tensor(1j, dtype=dtype_complex, device=device)\n",
        "\n",
        "        if thicknesses_nm.ndim == 1:\n",
        "            thicknesses_nm = thicknesses_nm.unsqueeze(0)  # (1, 3)\n",
        "        B = thicknesses_nm.shape[0]  # batch size\n",
        "\n",
        "        # Convert to meters\n",
        "        thicknesses_m = thicknesses_nm * 1e-9  # (B, 3)\n",
        "\n",
        "        # (B, 3, 401): broadcasting layer Ã— wavelength\n",
        "        delta = thicknesses_m[:, :, None] * self.k0[None, None, :] * self.n_list[None, :, :]\n",
        "\n",
        "        cosÎ´ = torch.cos(delta)\n",
        "        sinÎ´ = torch.sin(delta)\n",
        "\n",
        "        # ì´ˆê¸° M_total: (B, 401, 2, 2)\n",
        "        M_total = torch.eye(2, dtype=dtype_complex, device=device).repeat(B, self.num_wavelengths, 1, 1)\n",
        "\n",
        "        for j in range(self.num_layers):\n",
        "            Yj = self.n_list[j] * 2.654e-3  # (401,)\n",
        "\n",
        "            sin_j = sinÎ´[:, j, :]\n",
        "            cos_j = cosÎ´[:, j, :]\n",
        "\n",
        "            m11 = cos_j\n",
        "            m12 = imag_unit * sin_j / Yj[None, :]\n",
        "            m21 = imag_unit * Yj[None, :] * sin_j\n",
        "            m22 = cos_j\n",
        "\n",
        "            Mj = torch.stack([\n",
        "                torch.stack([m11, m12], dim=-1),\n",
        "                torch.stack([m21, m22], dim=-1)\n",
        "            ], dim=-2)  # shape: (B, 401, 2, 2)\n",
        "\n",
        "            M_total = torch.matmul(M_total, Mj)\n",
        "\n",
        "        Y_in = self.n_i * 2.654e-3\n",
        "        Y_out = self.n_s * 2.654e-3\n",
        "\n",
        "        B_ = M_total[:, :, 0, 0] + M_total[:, :, 0, 1] * Y_out\n",
        "        C_ = M_total[:, :, 1, 0] + M_total[:, :, 1, 1] * Y_out\n",
        "        denom = Y_in * B_ + C_\n",
        "        t1 = (2 * Y_in) / denom  # (B, 401)\n",
        "\n",
        "        T = (torch.real(self.n_s) / torch.real(self.n_i)) * torch.abs(t1) ** 2\n",
        "        return T.to(torch.float64)  # (B, 401)\n",
        "\n",
        "model = TMMNetwork(n_list_torch, n_i_torch, n_s_torch, Î»_tensor_global).to(device)"
      ],
      "metadata": {
        "id": "V33NauzAxlVI"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# ------------------------------\n",
        "# ì‹œë“œ ê³ ì • (ì¬í˜„ì„± í™•ë³´)\n",
        "# ------------------------------\n",
        "def seed_everything(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)  # if using multi-GPU\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "seed_everything(42)  # ì‹œë“œ ê³ ì • ì‹¤í–‰"
      ],
      "metadata": {
        "id": "5p_PSFaJx_Y3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "from torch.utils.data import random_split\n",
        "all_d = []\n",
        "all_T_target = []\n",
        "\n",
        "print(\"Generating (normalized_d â†’ T_target) pairs ...\")\n",
        "for d1 in d1_list_nm:\n",
        "    for d2 in d2_list_nm:\n",
        "        for d3 in d3_list_nm:\n",
        "            # (a) [d1, d2, d3]\n",
        "            d_nm_vec = torch.tensor([[d1, d2, d3]], dtype=torch.float64)  # shape: (1, 3)\n",
        "            all_d.append(d_nm_vec.cpu().numpy())\n",
        "            # (b) TMM forward\n",
        "            T_spec = model(d_nm_vec.to(device))  # forward(nm ë‹¨ìœ„ ë‘ê»˜)\n",
        "            all_T_target.append(T_spec.detach().cpu().numpy())\n",
        "# NumPy ë°°ì—´ë¡œ ë³€í™˜\n",
        "all_d = np.array(all_d, dtype=np.float64)   # shape: (3096, 3)\n",
        "#ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ë‘ê»˜í‘œì¤€í™”ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡\n",
        "THICKNESS_MIN = torch.tensor(np.min(all_d, axis=0), dtype=torch.float64, device=device)\n",
        "THICKNESS_MAX = torch.tensor(np.max(all_d, axis=0), dtype=torch.float64, device=device)\n",
        "def standardize_thickness(d_nm_array):\n",
        "    d_nm_array = torch.tensor(d_nm_array, dtype=torch.float64, device=THICKNESS_MIN.device) if not isinstance(d_nm_array, torch.Tensor) else d_nm_array.to(dtype=torch.float64, device=THICKNESS_MIN.device)\n",
        "    return (d_nm_array - THICKNESS_MIN) / (THICKNESS_MAX - THICKNESS_MIN)\n",
        "\n",
        "def destandardize_thickness(d_norm_array):\n",
        "    d_norm_array = d_norm_array.clone().to(dtype=torch.float64, device=THICKNESS_MIN.device)\n",
        "    return d_norm_array * (THICKNESS_MAX - THICKNESS_MIN) + THICKNESS_MIN\n",
        "\n",
        "all_d_norm = standardize_thickness(all_d)  # shape: (3096, 3)\n",
        "d_nm_check = destandardize_thickness(all_d_norm)\n",
        "\n",
        "\n",
        "#ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ìŠ¤í™íŠ¸ëŸ¼í‘œì¤€í™”ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡\n",
        "all_T_target = np.array(all_T_target, dtype=np.float64) # shape: (3096, 401)\n",
        "print(\"Total samples:\", all_d.shape[0])  # 3096\n",
        "\n",
        "SPECTRUM_MIN = torch.tensor(np.min(all_T_target, axis=0), dtype=torch.float64).to(device)\n",
        "SPECTRUM_MAX = torch.tensor(np.max(all_T_target, axis=0), dtype=torch.float64).to(device)\n",
        "def standardize_spectrum(T_array):\n",
        "    T_tensor = torch.tensor(T_array, dtype=torch.float64).to(device)\n",
        "    return (T_tensor - SPECTRUM_MIN) / (SPECTRUM_MAX - SPECTRUM_MIN)\n",
        "\n",
        "def destandardize_spectrum(T_std_array):\n",
        "    return T_std_array * (SPECTRUM_MAX - SPECTRUM_MIN) + SPECTRUM_MIN\n",
        "\n",
        "# destandardize_spectrumì˜ ê²°ê³¼(GPU í…ì„œ)ë¥¼ .cpu().numpy()ë¡œ ë³€í™˜í•˜ì—¬ ë¹„êµí•©ë‹ˆë‹¤.\n",
        "all_T_target_std = standardize_spectrum(all_T_target)\n",
        "restored_T = destandardize_spectrum(all_T_target_std)\n",
        "assert np.allclose(restored_T.cpu().numpy(), all_T_target, atol=1e-5)\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# (B) Dataset / DataLoader êµ¬ì¶•\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "class BiTMMNormalizedDataset(Dataset):\n",
        "    def __init__(self, d_norm_array, T_array):\n",
        "        self.d_norm = d_norm_array.clone().to(dtype=torch.float64)\n",
        "        self.T_spec = T_array.clone().detach().to(dtype=torch.float64) if isinstance(T_array, torch.Tensor) else torch.tensor(T_array, dtype=torch.float64)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.d_norm.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            'd_norm': self.d_norm[idx],       # shape: (3,)1\n",
        "            'T_target': self.T_spec[idx]      # shape: (401,)\n",
        "        }\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "\n",
        "# ì‹œë“œ ê³ ì •\n",
        "seed = 42\n",
        "g = torch.Generator().manual_seed(seed)\n",
        "\n",
        "# Dataset ìƒì„±\n",
        "dataset = BiTMMNormalizedDataset(all_d_norm, all_T_target_std)\n",
        "\n",
        "# ì „ì²´ ê¸¸ì´ ë° split ë¹„ìœ¨\n",
        "total_size = len(dataset)\n",
        "train_size = int(0.9 * total_size)\n",
        "val_size   = int(0.05 * total_size)\n",
        "test_size  = total_size - train_size - val_size  # ë‚˜ë¨¸ì§€\n",
        "\n",
        "print(f\"Total: {total_size}, Train: {train_size}, Val: {val_size}, Test: {test_size}\")\n",
        "\n",
        "# Dataset ë¶„í• \n",
        "train_dataset, val_dataset, test_dataset = random_split(\n",
        "    dataset, [train_size, val_size, test_size], generator=g  # gë¡œ í†µì¼\n",
        ")\n",
        "\n",
        "# DataLoader ì •ì˜\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,  num_workers=0, generator=g)\n",
        "val_loader   = DataLoader(val_dataset,   batch_size=batch_size, shuffle=False, num_workers=0)\n",
        "test_loader  = DataLoader(test_dataset,  batch_size=batch_size, shuffle=False, num_workers=0)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "suR-NIYM9jjV",
        "outputId": "7799abb3-fd68-40ed-c692-6e97d5a3c026"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating (normalized_d â†’ T_target) pairs ...\n",
            "Total samples: 8384\n",
            "Total: 8384, Train: 7545, Val: 419, Test: 420\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Forward Training **"
      ],
      "metadata": {
        "id": "GF1IxuMUxqpY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# [1] ëª¨ë¸ ì •ì˜: ForwardNet\n",
        "# - ì…ë ¥: ì •ê·œí™”ëœ ë‘ê»˜ ë²¡í„° (3ì°¨ì›)\n",
        "# - ì¶œë ¥: ì •ê·œí™”ëœ ìŠ¤í™íŠ¸ëŸ¼ ë²¡í„° (401ì°¨ì›)\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "# MLP ê° ì¸µì˜ ë‰´ëŸ° ìˆ˜ (ì‹¤í—˜ì ìœ¼ë¡œ ì„¤ì •ëœ ê°’)\n",
        "N1 = 1190\n",
        "N2 = 824\n",
        "N3 = 920\n",
        "\n",
        "class ForwardNet(nn.Module):\n",
        "    def __init__(self, input_dim=3, output_dim=401):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(3, N1),   # ì…ë ¥ì¸µ â†’ ì²« ë²ˆì§¸ ì€ë‹‰ì¸µ\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(N1, N2),  # ì²« ë²ˆì§¸ â†’ ë‘ ë²ˆì§¸ ì€ë‹‰ì¸µ\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(N2, N3),  # ë‘ ë²ˆì§¸ â†’ ì„¸ ë²ˆì§¸ ì€ë‹‰ì¸µ\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(N3, 401)  # ì„¸ ë²ˆì§¸ â†’ ì¶œë ¥ì¸µ (ìŠ¤í™íŠ¸ëŸ¼ 401í¬ì¸íŠ¸)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# [2] ëª¨ë¸ ë° ì˜µí‹°ë§ˆì´ì € ì´ˆê¸°í™”\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "# ëª¨ë¸ì„ GPU + float64ë¡œ ì´ˆê¸°í™”\n",
        "forward_net = ForwardNet(input_dim=3, output_dim=401).to(device).to(torch.float64)\n",
        "\n",
        "# ì˜µí‹°ë§ˆì´ì €: Adam, ì´ˆê¸° í•™ìŠµë¥  1e-3\n",
        "optimizer = torch.optim.Adam(forward_net.parameters(), lr=1e-3)\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# [3] í•™ìŠµ ê´€ë ¨ íŒŒë¼ë¯¸í„° ì„¤ì •\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "num_epochs = 600  # ì „ì²´ í•™ìŠµ epoch ìˆ˜\n",
        "\n",
        "# í•™ìŠµ ê²°ê³¼ë¥¼ ì €ì¥í•  ë””ë ‰í† ë¦¬ ìƒì„±\n",
        "output_dir = \"C:/Users/PC/Desktop/Deep/\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# í•™ìŠµ ë° ê²€ì¦ ì†ì‹¤ ê¸°ë¡ìš© ë¦¬ìŠ¤íŠ¸\n",
        "train_loss_history = []\n",
        "val_loss_history = []\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# [4] í•™ìŠµ ë£¨í”„ ì‹œì‘\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "for epoch in range(num_epochs):\n",
        "    forward_net.train()  # í•™ìŠµ ëª¨ë“œ ì „í™˜\n",
        "    total_loss = 0.0     # ëˆ„ì  ì†ì‹¤ ì´ˆê¸°í™”\n",
        "\n",
        "    # â–¶ í•œ epoch ë™ì•ˆ ì „ì²´ train_loader ìˆœíšŒ\n",
        "    for batch in train_loader:\n",
        "        d_norm = batch['d_norm'].to(device)        # ì…ë ¥: ì •ê·œí™”ëœ ë‘ê»˜ [B, 3]\n",
        "        T_target = batch['T_target'].to(device)    # ì •ë‹µ: ì •ê·œí™”ëœ ìŠ¤í™íŠ¸ëŸ¼ [B, 401]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        T_pred = forward_net(d_norm)               # ëª¨ë¸ ì˜ˆì¸¡\n",
        "\n",
        "        loss = F.mse_loss(T_pred, T_target)        # í‰ê·  ì œê³± ì˜¤ì°¨\n",
        "        loss.backward()                            # ì—­ì „íŒŒ\n",
        "        optimizer.step()                           # ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸\n",
        "        total_loss += loss.item()                  # ì†ì‹¤ ëˆ„ì \n",
        "\n",
        "    # â–¶ í‰ê·  í•™ìŠµ ì†ì‹¤ ê³„ì‚° ë° ê¸°ë¡\n",
        "    avg_train_loss = total_loss / len(train_loader)\n",
        "    train_loss_history.append(avg_train_loss)\n",
        "    print(f\"[Train] Epoch {epoch+1}, Avg Loss = {avg_train_loss:.6f}\")\n",
        "\n",
        "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    # [5] ê²€ì¦ ë£¨í”„ (Validation)\n",
        "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    forward_net.eval()        # í‰ê°€ ëª¨ë“œ ì „í™˜\n",
        "    val_loss_total = 0.0\n",
        "\n",
        "    with torch.no_grad():    # ê·¸ë˜ë””ì–¸íŠ¸ ë¹„í™œì„±í™” (ë©”ëª¨ë¦¬ ì ˆì•½)\n",
        "        for batch in val_loader:\n",
        "            d_norm = batch['d_norm'].to(device)\n",
        "            T_target = batch['T_target'].to(device)\n",
        "\n",
        "            T_pred = forward_net(d_norm)           # ì˜ˆì¸¡\n",
        "            loss = F.mse_loss(T_pred, T_target)    # ì†ì‹¤ ê³„ì‚°\n",
        "            val_loss_total += loss.item()\n",
        "\n",
        "    # â–¶ í‰ê·  ê²€ì¦ ì†ì‹¤ ê³„ì‚° ë° ê¸°ë¡\n",
        "    avg_val_loss = val_loss_total / len(val_loader)\n",
        "    val_loss_history.append(avg_val_loss)\n",
        "    print(f\"[Val]   Epoch [{epoch+1}/{num_epochs}] done. Avg Loss: {avg_val_loss:.6f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lsU_1U9mxoxo",
        "outputId": "37a4f662-2832-4875-d926-cd88c4b02d4f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train] Epoch 1, Avg Loss = 0.024856\n",
            "[Val]   Epoch [1/600] done. Avg Loss: 0.022393\n",
            "[Train] Epoch 2, Avg Loss = 0.022374\n",
            "[Val]   Epoch [2/600] done. Avg Loss: 0.021987\n",
            "[Train] Epoch 3, Avg Loss = 0.021553\n",
            "[Val]   Epoch [3/600] done. Avg Loss: 0.020566\n",
            "[Train] Epoch 4, Avg Loss = 0.020332\n",
            "[Val]   Epoch [4/600] done. Avg Loss: 0.018631\n",
            "[Train] Epoch 5, Avg Loss = 0.018621\n",
            "[Val]   Epoch [5/600] done. Avg Loss: 0.018245\n",
            "[Train] Epoch 6, Avg Loss = 0.016813\n",
            "[Val]   Epoch [6/600] done. Avg Loss: 0.014914\n",
            "[Train] Epoch 7, Avg Loss = 0.014887\n",
            "[Val]   Epoch [7/600] done. Avg Loss: 0.013470\n",
            "[Train] Epoch 8, Avg Loss = 0.013610\n",
            "[Val]   Epoch [8/600] done. Avg Loss: 0.011817\n",
            "[Train] Epoch 9, Avg Loss = 0.012065\n",
            "[Val]   Epoch [9/600] done. Avg Loss: 0.010882\n",
            "[Train] Epoch 10, Avg Loss = 0.010592\n",
            "[Val]   Epoch [10/600] done. Avg Loss: 0.009454\n",
            "[Train] Epoch 11, Avg Loss = 0.008899\n",
            "[Val]   Epoch [11/600] done. Avg Loss: 0.008016\n",
            "[Train] Epoch 12, Avg Loss = 0.007298\n",
            "[Val]   Epoch [12/600] done. Avg Loss: 0.006803\n",
            "[Train] Epoch 13, Avg Loss = 0.006188\n",
            "[Val]   Epoch [13/600] done. Avg Loss: 0.006109\n",
            "[Train] Epoch 14, Avg Loss = 0.005444\n",
            "[Val]   Epoch [14/600] done. Avg Loss: 0.005259\n",
            "[Train] Epoch 15, Avg Loss = 0.005134\n",
            "[Val]   Epoch [15/600] done. Avg Loss: 0.005510\n",
            "[Train] Epoch 16, Avg Loss = 0.004906\n",
            "[Val]   Epoch [16/600] done. Avg Loss: 0.004476\n",
            "[Train] Epoch 17, Avg Loss = 0.004375\n",
            "[Val]   Epoch [17/600] done. Avg Loss: 0.004404\n",
            "[Train] Epoch 18, Avg Loss = 0.004259\n",
            "[Val]   Epoch [18/600] done. Avg Loss: 0.005044\n",
            "[Train] Epoch 19, Avg Loss = 0.003994\n",
            "[Val]   Epoch [19/600] done. Avg Loss: 0.003750\n",
            "[Train] Epoch 20, Avg Loss = 0.003850\n",
            "[Val]   Epoch [20/600] done. Avg Loss: 0.004028\n",
            "[Train] Epoch 21, Avg Loss = 0.003699\n",
            "[Val]   Epoch [21/600] done. Avg Loss: 0.003873\n",
            "[Train] Epoch 22, Avg Loss = 0.003524\n",
            "[Val]   Epoch [22/600] done. Avg Loss: 0.003452\n",
            "[Train] Epoch 23, Avg Loss = 0.003336\n",
            "[Val]   Epoch [23/600] done. Avg Loss: 0.003245\n",
            "[Train] Epoch 24, Avg Loss = 0.003273\n",
            "[Val]   Epoch [24/600] done. Avg Loss: 0.003301\n",
            "[Train] Epoch 25, Avg Loss = 0.003220\n",
            "[Val]   Epoch [25/600] done. Avg Loss: 0.003259\n",
            "[Train] Epoch 26, Avg Loss = 0.003088\n",
            "[Val]   Epoch [26/600] done. Avg Loss: 0.003138\n",
            "[Train] Epoch 27, Avg Loss = 0.003140\n",
            "[Val]   Epoch [27/600] done. Avg Loss: 0.003072\n",
            "[Train] Epoch 28, Avg Loss = 0.002849\n",
            "[Val]   Epoch [28/600] done. Avg Loss: 0.003627\n",
            "[Train] Epoch 29, Avg Loss = 0.003099\n",
            "[Val]   Epoch [29/600] done. Avg Loss: 0.002832\n",
            "[Train] Epoch 30, Avg Loss = 0.002841\n",
            "[Val]   Epoch [30/600] done. Avg Loss: 0.003006\n",
            "[Train] Epoch 31, Avg Loss = 0.002669\n",
            "[Val]   Epoch [31/600] done. Avg Loss: 0.002655\n",
            "[Train] Epoch 32, Avg Loss = 0.002755\n",
            "[Val]   Epoch [32/600] done. Avg Loss: 0.002817\n",
            "[Train] Epoch 33, Avg Loss = 0.002498\n",
            "[Val]   Epoch [33/600] done. Avg Loss: 0.002542\n",
            "[Train] Epoch 34, Avg Loss = 0.002665\n",
            "[Val]   Epoch [34/600] done. Avg Loss: 0.002475\n",
            "[Train] Epoch 35, Avg Loss = 0.002476\n",
            "[Val]   Epoch [35/600] done. Avg Loss: 0.002882\n",
            "[Train] Epoch 36, Avg Loss = 0.002606\n",
            "[Val]   Epoch [36/600] done. Avg Loss: 0.002347\n",
            "[Train] Epoch 37, Avg Loss = 0.002513\n",
            "[Val]   Epoch [37/600] done. Avg Loss: 0.002214\n",
            "[Train] Epoch 38, Avg Loss = 0.002279\n",
            "[Val]   Epoch [38/600] done. Avg Loss: 0.002319\n",
            "[Train] Epoch 39, Avg Loss = 0.002229\n",
            "[Val]   Epoch [39/600] done. Avg Loss: 0.002574\n",
            "[Train] Epoch 40, Avg Loss = 0.002162\n",
            "[Val]   Epoch [40/600] done. Avg Loss: 0.002138\n",
            "[Train] Epoch 41, Avg Loss = 0.002250\n",
            "[Val]   Epoch [41/600] done. Avg Loss: 0.002252\n",
            "[Train] Epoch 42, Avg Loss = 0.002579\n",
            "[Val]   Epoch [42/600] done. Avg Loss: 0.003562\n",
            "[Train] Epoch 43, Avg Loss = 0.002329\n",
            "[Val]   Epoch [43/600] done. Avg Loss: 0.002238\n",
            "[Train] Epoch 44, Avg Loss = 0.002010\n",
            "[Val]   Epoch [44/600] done. Avg Loss: 0.002145\n",
            "[Train] Epoch 45, Avg Loss = 0.002150\n",
            "[Val]   Epoch [45/600] done. Avg Loss: 0.002143\n",
            "[Train] Epoch 46, Avg Loss = 0.002121\n",
            "[Val]   Epoch [46/600] done. Avg Loss: 0.002469\n",
            "[Train] Epoch 47, Avg Loss = 0.002216\n",
            "[Val]   Epoch [47/600] done. Avg Loss: 0.002030\n",
            "[Train] Epoch 48, Avg Loss = 0.001905\n",
            "[Val]   Epoch [48/600] done. Avg Loss: 0.002415\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-7-2573985307.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m                            \u001b[0;31m# ì—­ì „íŒŒ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m                           \u001b[0;31m# ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m                  \u001b[0;31m# ì†ì‹¤ ëˆ„ì \u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;31m# â–¶ í‰ê·  í•™ìŠµ ì†ì‹¤ ê³„ì‚° ë° ê¸°ë¡\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# (C) InverseNet ì •ì˜ (MLP)\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "t_path = '/content/drive/MyDrive/Colab Notebooks/Bi-directional20250402'\n",
        "os.makedirs(t_path, exist_ok=True)\n",
        "num_layers = len(material_sequence)  # 3\n",
        "class InverseNet(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, 1198),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1198, 1125),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1125, 853),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(853, 1411),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1411, 1320),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1320, 1958),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1958, output_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x must be shape (B, input_dim)\n",
        "        return self.net(x)\n",
        "\n",
        "\n",
        "inverse_net = InverseNet(input_dim=NUM_WAVELENGTHS, output_dim=num_layers).to(device)\n",
        "inverse_net = inverse_net.to(torch.float64)\n",
        "optimizer = optim.Adam(inverse_net.parameters(), lr=0.0016277391324458217)\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# (D) í•™ìŠµ ë£¨í”„\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "num_epochs = 600\n",
        "alpha = 1.0616785666328346\n",
        "forward_net.eval()\n",
        "for epoch in range(num_epochs):\n",
        "    inverse_net.train()\n",
        "    total_loss = 0.0\n",
        "    for batch_idx, batch in enumerate(train_loader):\n",
        "        T_target = batch['T_target'].to(device)      # [B, 401]\n",
        "        d_norm_true = batch['d_norm'].to(device)     # [B, 3]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        d_norm_pred = inverse_net(T_target.to(torch.float64)).squeeze(1)\n",
        "\n",
        "        if batch_idx == 0:\n",
        "            print(f\"\\n[DEBUG] Epoch {epoch+1}, Batch {batch_idx+1}\")\n",
        "        d_nm_pred = destandardize_thickness(d_norm_pred)\n",
        "        d_nm_true = destandardize_thickness(d_norm_true)\n",
        "\n",
        "        T_pred_batch = model(d_nm_pred)\n",
        "        squeezed_T_target = T_target.squeeze(1)\n",
        "        T_target_destd = destandardize_spectrum(squeezed_T_target)\n",
        "\n",
        "        loss_spectrum = F.mse_loss(T_pred_batch, T_target_destd)\n",
        "        loss_thickness = F.mse_loss(d_norm_pred, d_norm_true.squeeze(1))\n",
        "\n",
        "        if epoch < 18:\n",
        "            loss = loss_spectrum + alpha * loss_thickness\n",
        "        else:\n",
        "            loss = loss_spectrum\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_train_loss = total_loss / len(train_loader)\n",
        "    print(f\"[Train] Epoch [{epoch+1}/{num_epochs}] done. Avg Loss: {avg_train_loss:.6f}\")\n",
        "\n",
        "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    # Validation\n",
        "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    inverse_net.eval()\n",
        "    val_loss_total = 0.0\n",
        "    with torch.no_grad():\n",
        "        for val_batch in val_loader:\n",
        "            T_val = val_batch['T_target'].to(device)\n",
        "            d_norm_val = val_batch['d_norm'].to(device)\n",
        "\n",
        "            d_pred_val = inverse_net(T_val.to(torch.float64)).squeeze(1)\n",
        "            d_nm_val_pred = destandardize_thickness(d_pred_val)\n",
        "            T_val_pred = model(d_nm_val_pred)\n",
        "\n",
        "            T_val_destd = destandardize_spectrum(T_val.squeeze(1))\n",
        "\n",
        "            loss_val_spectrum = F.mse_loss(T_val_pred, T_val_destd)\n",
        "            loss_val_thickness = F.mse_loss(d_pred_val, d_norm_val.squeeze(1))\n",
        "\n",
        "            if epoch < 18:\n",
        "                val_loss = loss_val_spectrum + alpha * loss_val_thickness\n",
        "            else:\n",
        "                val_loss = loss_val_spectrum\n",
        "\n",
        "            val_loss_total += val_loss.item()\n",
        "\n",
        "    avg_val_loss = val_loss_total / len(val_loader)\n",
        "    print(f\"[Val]   Epoch [{epoch+1}/{num_epochs}] done. Avg Loss: {avg_val_loss:.6f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9oRdmem4aZ1_",
        "outputId": "2c605ab9-ca00-46c8-84ee-b02caf6c7ac2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[DEBUG] Epoch 1, Batch 1\n",
            "[Train] Epoch [1/600] done. Avg Loss: 0.138271\n",
            "[Val]   Epoch [1/600] done. Avg Loss: 0.126636\n",
            "\n",
            "[DEBUG] Epoch 2, Batch 1\n",
            "[Train] Epoch [2/600] done. Avg Loss: 0.123173\n",
            "[Val]   Epoch [2/600] done. Avg Loss: 0.125824\n",
            "\n",
            "[DEBUG] Epoch 3, Batch 1\n",
            "[Train] Epoch [3/600] done. Avg Loss: 0.118725\n",
            "[Val]   Epoch [3/600] done. Avg Loss: 0.107659\n",
            "\n",
            "[DEBUG] Epoch 4, Batch 1\n",
            "[Train] Epoch [4/600] done. Avg Loss: 0.106658\n",
            "[Val]   Epoch [4/600] done. Avg Loss: 0.098445\n",
            "\n",
            "[DEBUG] Epoch 5, Batch 1\n",
            "[Train] Epoch [5/600] done. Avg Loss: 0.100070\n",
            "[Val]   Epoch [5/600] done. Avg Loss: 0.096010\n",
            "\n",
            "[DEBUG] Epoch 6, Batch 1\n",
            "[Train] Epoch [6/600] done. Avg Loss: 0.097049\n",
            "[Val]   Epoch [6/600] done. Avg Loss: 0.089660\n",
            "\n",
            "[DEBUG] Epoch 7, Batch 1\n",
            "[Train] Epoch [7/600] done. Avg Loss: 0.095435\n",
            "[Val]   Epoch [7/600] done. Avg Loss: 0.092927\n",
            "\n",
            "[DEBUG] Epoch 8, Batch 1\n",
            "[Train] Epoch [8/600] done. Avg Loss: 0.089577\n",
            "[Val]   Epoch [8/600] done. Avg Loss: 0.083823\n",
            "\n",
            "[DEBUG] Epoch 9, Batch 1\n",
            "[Train] Epoch [9/600] done. Avg Loss: 0.078315\n",
            "[Val]   Epoch [9/600] done. Avg Loss: 0.075152\n",
            "\n",
            "[DEBUG] Epoch 10, Batch 1\n",
            "[Train] Epoch [10/600] done. Avg Loss: 0.072024\n",
            "[Val]   Epoch [10/600] done. Avg Loss: 0.068288\n",
            "\n",
            "[DEBUG] Epoch 11, Batch 1\n",
            "[Train] Epoch [11/600] done. Avg Loss: 0.068013\n",
            "[Val]   Epoch [11/600] done. Avg Loss: 0.075916\n",
            "\n",
            "[DEBUG] Epoch 12, Batch 1\n",
            "[Train] Epoch [12/600] done. Avg Loss: 0.066073\n",
            "[Val]   Epoch [12/600] done. Avg Loss: 0.068439\n",
            "\n",
            "[DEBUG] Epoch 13, Batch 1\n",
            "[Train] Epoch [13/600] done. Avg Loss: 0.066152\n",
            "[Val]   Epoch [13/600] done. Avg Loss: 0.059132\n",
            "\n",
            "[DEBUG] Epoch 14, Batch 1\n",
            "[Train] Epoch [14/600] done. Avg Loss: 0.062155\n",
            "[Val]   Epoch [14/600] done. Avg Loss: 0.063628\n",
            "\n",
            "[DEBUG] Epoch 15, Batch 1\n",
            "[Train] Epoch [15/600] done. Avg Loss: 0.062215\n",
            "[Val]   Epoch [15/600] done. Avg Loss: 0.061032\n",
            "\n",
            "[DEBUG] Epoch 16, Batch 1\n",
            "[Train] Epoch [16/600] done. Avg Loss: 0.060361\n",
            "[Val]   Epoch [16/600] done. Avg Loss: 0.056488\n",
            "\n",
            "[DEBUG] Epoch 17, Batch 1\n",
            "[Train] Epoch [17/600] done. Avg Loss: 0.058385\n",
            "[Val]   Epoch [17/600] done. Avg Loss: 0.059092\n",
            "\n",
            "[DEBUG] Epoch 18, Batch 1\n",
            "[Train] Epoch [18/600] done. Avg Loss: 0.057843\n",
            "[Val]   Epoch [18/600] done. Avg Loss: 0.055955\n",
            "\n",
            "[DEBUG] Epoch 19, Batch 1\n",
            "[Train] Epoch [19/600] done. Avg Loss: 0.013480\n",
            "[Val]   Epoch [19/600] done. Avg Loss: 0.010588\n",
            "\n",
            "[DEBUG] Epoch 20, Batch 1\n",
            "[Train] Epoch [20/600] done. Avg Loss: 0.011821\n",
            "[Val]   Epoch [20/600] done. Avg Loss: 0.010942\n",
            "\n",
            "[DEBUG] Epoch 21, Batch 1\n",
            "[Train] Epoch [21/600] done. Avg Loss: 0.011594\n",
            "[Val]   Epoch [21/600] done. Avg Loss: 0.009289\n",
            "\n",
            "[DEBUG] Epoch 22, Batch 1\n",
            "[Train] Epoch [22/600] done. Avg Loss: 0.009811\n",
            "[Val]   Epoch [22/600] done. Avg Loss: 0.008799\n",
            "\n",
            "[DEBUG] Epoch 23, Batch 1\n",
            "[Train] Epoch [23/600] done. Avg Loss: 0.009447\n",
            "[Val]   Epoch [23/600] done. Avg Loss: 0.007516\n",
            "\n",
            "[DEBUG] Epoch 24, Batch 1\n",
            "[Train] Epoch [24/600] done. Avg Loss: 0.008896\n",
            "[Val]   Epoch [24/600] done. Avg Loss: 0.008307\n",
            "\n",
            "[DEBUG] Epoch 25, Batch 1\n",
            "[Train] Epoch [25/600] done. Avg Loss: 0.009067\n",
            "[Val]   Epoch [25/600] done. Avg Loss: 0.007000\n",
            "\n",
            "[DEBUG] Epoch 26, Batch 1\n",
            "[Train] Epoch [26/600] done. Avg Loss: 0.009028\n",
            "[Val]   Epoch [26/600] done. Avg Loss: 0.006943\n",
            "\n",
            "[DEBUG] Epoch 27, Batch 1\n",
            "[Train] Epoch [27/600] done. Avg Loss: 0.009179\n",
            "[Val]   Epoch [27/600] done. Avg Loss: 0.006646\n",
            "\n",
            "[DEBUG] Epoch 28, Batch 1\n",
            "[Train] Epoch [28/600] done. Avg Loss: 0.008724\n",
            "[Val]   Epoch [28/600] done. Avg Loss: 0.009723\n",
            "\n",
            "[DEBUG] Epoch 29, Batch 1\n",
            "[Train] Epoch [29/600] done. Avg Loss: 0.007408\n",
            "[Val]   Epoch [29/600] done. Avg Loss: 0.010216\n",
            "\n",
            "[DEBUG] Epoch 30, Batch 1\n",
            "[Train] Epoch [30/600] done. Avg Loss: 0.013154\n",
            "[Val]   Epoch [30/600] done. Avg Loss: 0.012691\n",
            "\n",
            "[DEBUG] Epoch 31, Batch 1\n",
            "[Train] Epoch [31/600] done. Avg Loss: 0.010693\n",
            "[Val]   Epoch [31/600] done. Avg Loss: 0.008800\n",
            "\n",
            "[DEBUG] Epoch 32, Batch 1\n",
            "[Train] Epoch [32/600] done. Avg Loss: 0.010738\n",
            "[Val]   Epoch [32/600] done. Avg Loss: 0.007780\n",
            "\n",
            "[DEBUG] Epoch 33, Batch 1\n",
            "[Train] Epoch [33/600] done. Avg Loss: 0.008436\n",
            "[Val]   Epoch [33/600] done. Avg Loss: 0.011527\n",
            "\n",
            "[DEBUG] Epoch 34, Batch 1\n",
            "[Train] Epoch [34/600] done. Avg Loss: 0.009565\n",
            "[Val]   Epoch [34/600] done. Avg Loss: 0.009213\n",
            "\n",
            "[DEBUG] Epoch 35, Batch 1\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-8-3231285490.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0mavg_train_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import urllib.request\n",
        "\n",
        "class InverseNet(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, 1198),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1198, 1125),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1125, 853),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(853, 1411),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1411, 1320),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1320, 1958),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1958, output_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x must be shape (B, input_dim)\n",
        "        return self.net(x)\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 2. ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° (GitHub â†’ ë¡œì»¬ ì €ì¥ â†’ ëª¨ë¸ì— ë¡œë“œ)\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "inverse_net = InverseNet(input_dim=401, output_dim=3).to(device).to(torch.float64)\n",
        "\n",
        "# GitHubì—ì„œ íŒŒë¼ë¯¸í„° ë‹¤ìš´ë¡œë“œ\n",
        "url = \"https://raw.githubusercontent.com/KIMEUIJOON-KNU/Bi-directional/main/inverse_net_final.pth\"\n",
        "save_path = \"inverse_net_final.pth\"\n",
        "urllib.request.urlretrieve(url, save_path)\n",
        "\n",
        "# ë¡œë“œ\n",
        "inverse_net.load_state_dict(torch.load(save_path, map_location=device))\n",
        "inverse_net.eval()\n",
        "print(\"âœ… ëª¨ë¸ ë¡œë“œ ë° eval() ì „í™˜ ì™„ë£Œ\")\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 3. test dataset ì¶”ì¶œ (random splitëœ dataset ê¸°ë°˜)\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "from torch.utils.data import random_split, DataLoader\n",
        "\n",
        "# ì´ë¯¸ ì •ì˜ë˜ì–´ ìˆëŠ” dataset / train_size / val_size / test_size ì‚¬ìš©\n",
        "_, _, test_dataset = random_split(dataset, [train_size, val_size, test_size], generator=torch.Generator().manual_seed(42))\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 4. test set ì˜ˆì¸¡ ë° ê²°ê³¼ ì €ì¥\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "all_true_d, all_pred_d = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        T_test = batch['T_target'].to(device).squeeze(1)  # shape: [B, 401]\n",
        "        d_true_norm = batch['d_norm'].to(device)\n",
        "\n",
        "        # ì˜ˆì¸¡\n",
        "        d_pred_norm = inverse_net(T_test)\n",
        "\n",
        "        # ì •ê·œí™”ëœ ë‘ê»˜ â†’ ì‹¤ì œ ë‘ê»˜ë¡œ ë³µì›\n",
        "        d_pred_nm = destandardize_thickness(d_pred_norm).cpu().numpy()\n",
        "        d_true_nm = destandardize_thickness(d_true_norm).cpu().numpy()\n",
        "\n",
        "        all_true_d.append(d_true_nm)\n",
        "        all_pred_d.append(d_pred_nm)\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 5. DataFrameìœ¼ë¡œ ê²°ê³¼ ì •ë¦¬ (d1, d2, d3 ê° ë¹„êµ)\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "true_all = torch.tensor(np.concatenate(all_true_d, axis=0))\n",
        "pred_all = torch.tensor(np.concatenate(all_pred_d, axis=0))\n",
        "\n",
        "df_result = pd.DataFrame({\n",
        "    \"True_d1\": true_all[:, 0],\n",
        "    \"True_d2\": true_all[:, 1],\n",
        "    \"True_d3\": true_all[:, 2],\n",
        "    \"Pred_d1\": pred_all[:, 0],\n",
        "    \"Pred_d2\": pred_all[:, 1],\n",
        "    \"Pred_d3\": pred_all[:, 2],\n",
        "})\n",
        "\n",
        "# ìƒìœ„ 10ê°œ ì¶œë ¥\n",
        "print(df_result.head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "id": "0F9_GmzuQoV4",
        "outputId": "2288af52-c3b3-4b0f-a251-8b1b90a77dc1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Error(s) in loading state_dict for InverseNet:\n\tMissing key(s) in state_dict: \"net.10.weight\", \"net.10.bias\", \"net.12.weight\", \"net.12.bias\". \n\tsize mismatch for net.0.weight: copying a param with shape torch.Size([768, 401]) from checkpoint, the shape in current model is torch.Size([1198, 401]).\n\tsize mismatch for net.0.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1198]).\n\tsize mismatch for net.2.weight: copying a param with shape torch.Size([768, 768]) from checkpoint, the shape in current model is torch.Size([1125, 1198]).\n\tsize mismatch for net.2.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1125]).\n\tsize mismatch for net.4.weight: copying a param with shape torch.Size([768, 768]) from checkpoint, the shape in current model is torch.Size([853, 1125]).\n\tsize mismatch for net.4.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([853]).\n\tsize mismatch for net.6.weight: copying a param with shape torch.Size([768, 768]) from checkpoint, the shape in current model is torch.Size([1411, 853]).\n\tsize mismatch for net.6.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1411]).\n\tsize mismatch for net.8.weight: copying a param with shape torch.Size([3, 768]) from checkpoint, the shape in current model is torch.Size([1320, 1411]).\n\tsize mismatch for net.8.bias: copying a param with shape torch.Size([3]) from checkpoint, the shape in current model is torch.Size([1320]).",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-9-1800647458.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m# ë¡œë“œ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0minverse_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0minverse_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"âœ… ëª¨ë¸ ë¡œë“œ ë° eval() ì „í™˜ ì™„ë£Œ\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2580\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2581\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m   2582\u001b[0m                 \"Error(s) in loading state_dict for {}:\\n\\t{}\".format(\n\u001b[1;32m   2583\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n\\t\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for InverseNet:\n\tMissing key(s) in state_dict: \"net.10.weight\", \"net.10.bias\", \"net.12.weight\", \"net.12.bias\". \n\tsize mismatch for net.0.weight: copying a param with shape torch.Size([768, 401]) from checkpoint, the shape in current model is torch.Size([1198, 401]).\n\tsize mismatch for net.0.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1198]).\n\tsize mismatch for net.2.weight: copying a param with shape torch.Size([768, 768]) from checkpoint, the shape in current model is torch.Size([1125, 1198]).\n\tsize mismatch for net.2.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1125]).\n\tsize mismatch for net.4.weight: copying a param with shape torch.Size([768, 768]) from checkpoint, the shape in current model is torch.Size([853, 1125]).\n\tsize mismatch for net.4.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([853]).\n\tsize mismatch for net.6.weight: copying a param with shape torch.Size([768, 768]) from checkpoint, the shape in current model is torch.Size([1411, 853]).\n\tsize mismatch for net.6.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1411]).\n\tsize mismatch for net.8.weight: copying a param with shape torch.Size([3, 768]) from checkpoint, the shape in current model is torch.Size([1320, 1411]).\n\tsize mismatch for net.8.bias: copying a param with shape torch.Size([3]) from checkpoint, the shape in current model is torch.Size([1320])."
          ]
        }
      ]
    }
  ]
}