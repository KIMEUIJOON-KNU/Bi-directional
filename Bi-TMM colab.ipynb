{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OKdr0AFPWE7x"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **êµ´ì ˆë¥  ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (TMMìœ¼ë¡œ ë°ì´í„° ìƒì„±ì‹œ í•„ìš”)**"
      ],
      "metadata": {
        "id": "YVRJZWbMCPFP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6wcpY_qWA9B",
        "outputId": "3639700e-c808-492e-c82f-5f63f061f40d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ì¬ë£Œ ë¦¬ìŠ¤íŠ¸: ['SiO2', 'WO3', 'Ag']\n",
            "ì¬ë£Œ ì¸ë±ìŠ¤ ë§¤í•‘: {0: 'Ag', 1: 'SiO2', 2: 'WO3'}\n",
            "ì²˜ë¦¬ ì¤‘: SiO2_380.csv (materials: SiO2) â†’ https://raw.githubusercontent.com/KIMEUIJOON-KNU/Bi-directional/main/SiO2_380.csv\n",
            "ë¡œë“œ ì™„ë£Œ: 401 points\n",
            "ì²˜ë¦¬ ì¤‘: WO3_380.csv (materials: WO3) â†’ https://raw.githubusercontent.com/KIMEUIJOON-KNU/Bi-directional/main/WO3_380.csv\n",
            "ë¡œë“œ ì™„ë£Œ: 401 points\n",
            "ì²˜ë¦¬ ì¤‘: Ag_380.csv (materials: Ag) â†’ https://raw.githubusercontent.com/KIMEUIJOON-KNU/Bi-directional/main/Ag_380.csv\n",
            "ë¡œë“œ ì™„ë£Œ: 401 points\n",
            "Air êµ´ì ˆë¥  ì¶”ê°€ ì™„ë£Œ\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# íŒŒì¥ ì •ì˜\n",
        "WAVELENGTHS = np.arange(380, 781, 1)\n",
        "NUM_WAVELENGTHS = len(WAVELENGTHS) #401\n",
        "\n",
        "# GitHub raw ì£¼ì†Œ (íŒŒì¼ë“¤ì´ ìœ„ì¹˜í•œ ê²½ë¡œ)\n",
        "base_url = \"https://raw.githubusercontent.com/KIMEUIJOON-KNU/Bi-directional/main/\"\n",
        "\n",
        "# ì‚¬ìš©í•  ì¬ë£Œ ëª©ë¡\n",
        "material_files = [\n",
        "    ('SiO2', 'SiO2_380.csv'),\n",
        "    ('WO3',  'WO3_380.csv'),\n",
        "    ('Ag',   'Ag_380.csv')\n",
        "]\n",
        "\n",
        "material_data = {}\n",
        "material_names = [info[0] for info in material_files]\n",
        "print(\"ì¬ë£Œ ë¦¬ìŠ¤íŠ¸:\", material_names)\n",
        "\n",
        "# ì¬ë£Œ ì¸ë±ì‹± ë§¤í•‘\n",
        "material_names = sorted(set(material_names))\n",
        "material_to_index = {name: i for i, name in enumerate(material_names)}\n",
        "index_to_material = {i: name for name, i in material_to_index.items()}\n",
        "print(\"ì¬ë£Œ ì¸ë±ìŠ¤ ë§¤í•‘:\", index_to_material)\n",
        "\n",
        "# --- ì¬ë£Œ íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸° ---\n",
        "for material_name, filename in material_files:\n",
        "    file_url = base_url + filename\n",
        "    print(f\"ì²˜ë¦¬ ì¤‘: {filename} (materials: {material_name}) â†’ {file_url}\")\n",
        "    try:\n",
        "        data = pd.read_csv(file_url, header=None)\n",
        "    except Exception as e:\n",
        "        print(f\"  ğŸš« ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
        "        continue\n",
        "\n",
        "    if data.empty:\n",
        "        print(\"  âš ï¸ ê²½ê³ : íŒŒì¼ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.\")\n",
        "        continue\n",
        "\n",
        "    wavelengths = data.iloc[:, 0].values  # íŒŒì¥\n",
        "    n = data.iloc[:, 1].values           # ì‹¤ìˆ˜ë¶€\n",
        "    k = data.iloc[:, 2].values           # í—ˆìˆ˜ë¶€\n",
        "\n",
        "    n_complex = n + 1j * k               # ë³µì†Œ êµ´ì ˆë¥ \n",
        "\n",
        "    material_data[material_name] = (wavelengths, n_complex)\n",
        "    print(f\"ë¡œë“œ ì™„ë£Œ: {len(wavelengths)} points\")\n",
        "\n",
        "# --- ê³µê¸° êµ´ì ˆë¥  ì¶”ê°€ ---\n",
        "material_data['Air'] = np.ones(NUM_WAVELENGTHS, dtype=np.complex128)\n",
        "print(\"Air êµ´ì ˆë¥  ì¶”ê°€ ì™„ë£Œ\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xyfqaeLeBLec",
        "outputId": "a9069be9-3b78-41f8-a2b5-cc71349d4d2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8384\n"
          ]
        }
      ],
      "source": [
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# (1) íŒŒì¥ ì •ì˜ (380~780 nm, 1 nm ê°„ê²© â†’ ì´ 401ê°œ íŒŒì¥ ì§€ì )\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "Î»_tensor_global = torch.tensor(WAVELENGTHS, dtype=torch.float64).to(device) * 1e-9  # [m ë‹¨ìœ„ë¡œ ë³€í™˜ëœ íŒŒì¥ í…ì„œ]\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# (2) ì¸µë³„ ì¬ë£Œ ì •ì˜ (MIM êµ¬ì¡° ì˜ˆì‹œ: ê¸ˆì†-ì ˆì—°ì²´-ê¸ˆì†)\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "material_sequence = ['Ag', 'WO3', 'Ag']  # êµ¬ì¡°ì— ì‚¬ìš©ë  ì¬ë£Œ ìˆœì„œ (ì…ì‚¬ë©´ì—ì„œë¶€í„° ì•„ë˜ ë°©í–¥)\n",
        "\n",
        "# material_data ì—ì„œ ê° ì¬ë£Œì˜ ë³µì†Œ êµ´ì ˆë¥  (n + ik) ê°’ ì¶”ì¶œ (shape: [401])\n",
        "n_list_np_arrays = [material_data[mat][1] for mat in material_sequence]  # ê¸¸ì´ 3 ë¦¬ìŠ¤íŠ¸ (ê°ê° [401] í¬ê¸°)\n",
        "\n",
        "# numpy â†’ torch ë³€í™˜ í›„, complex64 í˜•ì‹ìœ¼ë¡œ ë¬¶ì–´ì„œ GPUë¡œ ì´ë™ (shape: [3, 401])\n",
        "n_list_torch = torch.stack([\n",
        "    torch.from_numpy(arr).to(torch.complex64) for arr in n_list_np_arrays\n",
        "], dim=0).to(device)\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# (3) ì…ì‚¬ ë§¤ì§ˆ (n_i)ì™€ ì¶œì‚¬ ë§¤ì§ˆ (n_s) ì„¤ì •\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "n_i_np = material_data['SiO2'][1]   # ì…ì‚¬ ë§¤ì§ˆ: SiO2ì˜ ë³µì†Œ êµ´ì ˆë¥  (n + ik)\n",
        "n_s_np = material_data['Air']       # ì¶œì‚¬ ë§¤ì§ˆ: Air (n=1, k=0)\n",
        "\n",
        "n_i_torch = torch.from_numpy(n_i_np).to(torch.complex64).to(device)  # torch ë³€í™˜ í›„ GPU ì´ë™\n",
        "n_s_torch = torch.from_numpy(n_s_np).to(torch.complex64).to(device)\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# (4) ë‘ê»˜ ê·¸ë¦¬ë“œ ì •ì˜ (nm ë‹¨ìœ„, ì´ ì¡°í•© ìˆ˜ = 8 * 187 * 8 = 11968ê°œ)\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "d1_list_nm = np.arange(5, 41, 5)      # ê¸ˆì†ì¸µ (d1): 5 ~ 40 nm, ê°„ê²© 5 nm â†’ ì´ 8ê°œ\n",
        "d2_list_nm = np.arange(150, 801, 5)    # ì ˆì—°ì¸µ (d2): 20 ~ 950 nm, ê°„ê²© 5 nm â†’ ì´ 187ê°œ\n",
        "d3_list_nm = np.arange(5, 41, 5)      # ê¸ˆì†ì¸µ (d3): 5 ~ 40 nm, ê°„ê²© 5 nm â†’ ì´ 8ê°œ\n",
        "\n",
        "print(len(d1_list_nm)*len(d2_list_nm)*len(d3_list_nm))  # ì´ ì¡°í•© ê°œìˆ˜ ì¶œë ¥ (8 Ã— 187 Ã— 8 = 11,968)\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# (5) ìƒ˜í”Œ ì €ì¥ìš© ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "all_d_tilde = []    # â–¶ ê° ìƒ˜í”Œì˜ (d1, d2, d3) ë‘ê»˜ ì¡°í•©ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸\n",
        "                    #   ì¼ë°˜ì ìœ¼ë¡œ ë‚˜ì¤‘ì— ì •ê·œí™”ëœ í˜•íƒœë¡œ ì €ì¥ë˜ë©° í•™ìŠµ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©\n",
        "\n",
        "all_T_target = []   # â–¶ ê° ì¡°í•©ì— ëŒ€ì‘í•˜ëŠ” ìŠ¤í™íŠ¸ëŸ¼ T(Î») [shape: (401,)] ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸\n",
        "                    #   Forward modelì„ í†µí•´ ê³„ì‚°ëœ ì •ë‹µ ìŠ¤í™íŠ¸ëŸ¼ (target)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hnFyPOo-v2xi"
      },
      "outputs": [],
      "source": [
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# (A-1) TMMNetwork ì •ì˜ (í´ë˜ìŠ¤ ì´ë¦„, dtype í†µì¼, calculate() ì¶”ê°€)\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "class TMMNetwork(nn.Module):\n",
        "    def __init__(self, n_list_input, n_i_input, n_s_input, wavelengths_m_tensor):\n",
        "        super().__init__()\n",
        "        dtype_complex = torch.complex128\n",
        "        dtype_float = torch.float64\n",
        "\n",
        "        n_list_real = n_list_input.real\n",
        "        n_list_imag = -torch.abs(n_list_input.imag)\n",
        "        self.register_buffer('n_list', torch.complex(n_list_real, n_list_imag))\n",
        "        self.register_buffer('n_i', n_i_input.to(dtype_complex))\n",
        "        self.register_buffer('n_s', n_s_input.to(dtype_complex))\n",
        "\n",
        "        # íŒŒìˆ˜ k0\n",
        "        k0 = 2 * torch.pi / torch.clamp(wavelengths_m_tensor, min=1e-20)\n",
        "        self.register_buffer('k0', k0)  # ì´ì œ k0_tilde ì•„ë‹˜\n",
        "\n",
        "        self.num_layers = self.n_list.shape[0]\n",
        "        self.num_wavelengths = wavelengths_m_tensor.shape[0]\n",
        "\n",
        "    def forward(self, thicknesses_nm):\n",
        "        device = thicknesses_nm.device\n",
        "        dtype_complex = torch.complex128\n",
        "        imag_unit = torch.tensor(1j, dtype=dtype_complex, device=device)\n",
        "\n",
        "        if thicknesses_nm.ndim == 1:\n",
        "            thicknesses_nm = thicknesses_nm.unsqueeze(0)  # (1, 3)\n",
        "        B = thicknesses_nm.shape[0]  # batch size\n",
        "\n",
        "        # Convert to meters\n",
        "        thicknesses_m = thicknesses_nm * 1e-9  # (B, 3)\n",
        "\n",
        "        # (B, 3, 401): broadcasting layer Ã— wavelength\n",
        "        delta = thicknesses_m[:, :, None] * self.k0[None, None, :] * self.n_list[None, :, :]\n",
        "\n",
        "        cosÎ´ = torch.cos(delta)\n",
        "        sinÎ´ = torch.sin(delta)\n",
        "\n",
        "        # ì´ˆê¸° M_total: (B, 401, 2, 2)\n",
        "        M_total = torch.eye(2, dtype=dtype_complex, device=device).repeat(B, self.num_wavelengths, 1, 1)\n",
        "\n",
        "        for j in range(self.num_layers):\n",
        "            Yj = self.n_list[j] * 2.654e-3  # (401,)\n",
        "\n",
        "            sin_j = sinÎ´[:, j, :]\n",
        "            cos_j = cosÎ´[:, j, :]\n",
        "\n",
        "            m11 = cos_j\n",
        "            m12 = imag_unit * sin_j / Yj[None, :]\n",
        "            m21 = imag_unit * Yj[None, :] * sin_j\n",
        "            m22 = cos_j\n",
        "\n",
        "            Mj = torch.stack([\n",
        "                torch.stack([m11, m12], dim=-1),\n",
        "                torch.stack([m21, m22], dim=-1)\n",
        "            ], dim=-2)  # shape: (B, 401, 2, 2)\n",
        "\n",
        "            M_total = torch.matmul(M_total, Mj)\n",
        "\n",
        "        Y_in = self.n_i * 2.654e-3\n",
        "        Y_out = self.n_s * 2.654e-3\n",
        "\n",
        "        B_ = M_total[:, :, 0, 0] + M_total[:, :, 0, 1] * Y_out\n",
        "        C_ = M_total[:, :, 1, 0] + M_total[:, :, 1, 1] * Y_out\n",
        "        denom = Y_in * B_ + C_\n",
        "        t1 = (2 * Y_in) / denom  # (B, 401)\n",
        "\n",
        "        T = (torch.real(self.n_s) / torch.real(self.n_i)) * torch.abs(t1) ** 2\n",
        "        return T.to(torch.float64)  # (B, 401)\n",
        "\n",
        "model = TMMNetwork(n_list_torch, n_i_torch, n_s_torch, Î»_tensor_global).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "awPhXGk1CHwC"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# ------------------------------\n",
        "# ì‹œë“œ ê³ ì • (ì¬í˜„ì„± í™•ë³´)\n",
        "# ------------------------------\n",
        "def seed_everything(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)  # if using multi-GPU\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "seed_everything(42)  # ì‹œë“œ ê³ ì • ì‹¤í–‰"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QB5wv5A3j8H",
        "outputId": "eaa3e2f7-a707-4b40-d855-1a98b2992ff9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating (normalized_d â†’ T_target) pairs ...\n",
            "Total samples: 8384\n",
            "Total: 8384, Train: 7545, Val: 419, Test: 420\n"
          ]
        }
      ],
      "source": [
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# (A) ë°ì´í„° ìƒì„±: (ë‘ê»˜ â†’ ìŠ¤í™íŠ¸ëŸ¼) via TMM\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "\n",
        "all_d = []           # â–¶ ê° ìƒ˜í”Œì˜ [d1, d2, d3] ë‘ê»˜ ì¡°í•© (ì •ê·œí™” ì „, nm)\n",
        "all_T_target = []    # â–¶ ê° ìƒ˜í”Œì— ëŒ€í•œ T(Î») ìŠ¤í™íŠ¸ëŸ¼ (shape: [401])\n",
        "\n",
        "print(\"Generating (normalized_d â†’ T_target) pairs ...\")\n",
        "\n",
        "for d1 in d1_list_nm:\n",
        "    for d2 in d2_list_nm:\n",
        "        for d3 in d3_list_nm:\n",
        "            d_nm_vec = torch.tensor([[d1, d2, d3]], dtype=torch.float64)  # shape: [1, 3]\n",
        "            all_d.append(d_nm_vec.cpu().numpy().squeeze(0))  # shape: [3]\n",
        "\n",
        "            T_spec = model(d_nm_vec.to(device))              # TMM forward (ì…ë ¥: nm ë‹¨ìœ„ ë‘ê»˜)\n",
        "            all_T_target.append(T_spec.detach().cpu().numpy())\n",
        "\n",
        "# â–¶ NumPy ë°°ì—´ë¡œ ë³€í™˜ (shape: [N, 3] / [N, 401])\n",
        "all_d = np.array(all_d, dtype=np.float64)\n",
        "all_T_target = np.array(all_T_target, dtype=np.float64)\n",
        "print(\"Total samples:\", all_d.shape[0])\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# (B) ë‘ê»˜ ì •ê·œí™” (Min-Max Scaling)\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "THICKNESS_MIN = torch.tensor(np.min(all_d, axis=0), dtype=torch.float64, device=device)\n",
        "THICKNESS_MAX = torch.tensor(np.max(all_d, axis=0), dtype=torch.float64, device=device)\n",
        "\n",
        "def standardize_thickness(d_nm_array):\n",
        "    \"\"\"ì…ë ¥: ì‹¤ì œ ë‘ê»˜ (nm), ì¶œë ¥: ì •ê·œí™”ëœ ë‘ê»˜ [0,1]\"\"\"\n",
        "    d_nm_array = torch.tensor(d_nm_array, dtype=torch.float64, device=device) if not isinstance(d_nm_array, torch.Tensor) else d_nm_array.to(dtype=torch.float64, device=device)\n",
        "    return (d_nm_array - THICKNESS_MIN) / (THICKNESS_MAX - THICKNESS_MIN)\n",
        "\n",
        "def destandardize_thickness(d_norm_array):\n",
        "    \"\"\"ì…ë ¥: ì •ê·œí™”ëœ ë‘ê»˜, ì¶œë ¥: ì‹¤ì œ ë‘ê»˜ (nm)\"\"\"\n",
        "    d_norm_array = d_norm_array.clone().to(dtype=torch.float64, device=device)\n",
        "    return d_norm_array * (THICKNESS_MAX - THICKNESS_MIN) + THICKNESS_MIN\n",
        "\n",
        "all_d_norm = standardize_thickness(all_d)                     # shape: [N, 3]\n",
        "d_nm_check = destandardize_thickness(all_d_norm)              # ì—­ë³€í™˜ í™•ì¸ìš©\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# (C) ìŠ¤í™íŠ¸ëŸ¼ ì •ê·œí™” (Min-Max Scaling per Î»)\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "SPECTRUM_MIN = torch.tensor(np.min(all_T_target, axis=0), dtype=torch.float64).to(device)\n",
        "SPECTRUM_MAX = torch.tensor(np.max(all_T_target, axis=0), dtype=torch.float64).to(device)\n",
        "\n",
        "def standardize_spectrum(T_array):\n",
        "    \"\"\"ì…ë ¥: ì›ë³¸ ìŠ¤í™íŠ¸ëŸ¼, ì¶œë ¥: [0,1] ì •ê·œí™”\"\"\"\n",
        "    T_tensor = torch.tensor(T_array, dtype=torch.float64).to(device)\n",
        "    return (T_tensor - SPECTRUM_MIN) / (SPECTRUM_MAX - SPECTRUM_MIN)\n",
        "\n",
        "def destandardize_spectrum(T_std_array):\n",
        "    \"\"\"ì…ë ¥: ì •ê·œí™”ëœ ìŠ¤í™íŠ¸ëŸ¼, ì¶œë ¥: ì›ë³¸ ìŠ¤í™íŠ¸ëŸ¼\"\"\"\n",
        "    return T_std_array * (SPECTRUM_MAX - SPECTRUM_MIN) + SPECTRUM_MIN\n",
        "\n",
        "# â–¶ ì •ê·œí™” ì ìš© + ì—­ë³€í™˜ ì²´í¬\n",
        "all_T_target_std = standardize_spectrum(all_T_target)\n",
        "restored_T = destandardize_spectrum(all_T_target_std)\n",
        "assert np.allclose(restored_T.cpu().numpy(), all_T_target, atol=1e-5)\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# (D) PyTorch Dataset ì •ì˜\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "class BiTMMNormalizedDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Bi-directional TMMìš© ë°ì´í„°ì…‹ í´ë˜ìŠ¤.\n",
        "    ì…ë ¥: ì •ê·œí™”ëœ ë‘ê»˜\n",
        "    ì¶œë ¥: ì •ê·œí™”ëœ ìŠ¤í™íŠ¸ëŸ¼\n",
        "    \"\"\"\n",
        "    def __init__(self, d_norm_array, T_array):\n",
        "        self.d_norm = d_norm_array.clone().to(dtype=torch.float64)\n",
        "        self.T_spec = T_array.clone().detach().to(dtype=torch.float64) if isinstance(T_array, torch.Tensor) else torch.tensor(T_array, dtype=torch.float64)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.d_norm.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            'd_norm': self.d_norm[idx],       # shape: [3]\n",
        "            'T_target': self.T_spec[idx]      # shape: [401]\n",
        "        }\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# (E) Dataset ë¶„í•  ë° DataLoader êµ¬ì„±\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "batch_size = 32\n",
        "seed = 42\n",
        "g = torch.Generator().manual_seed(seed)  # ì‹œë“œ ê³ ì •\n",
        "\n",
        "# â–¶ ì „ì²´ Dataset ìƒì„±\n",
        "dataset = BiTMMNormalizedDataset(all_d_norm, all_T_target_std)\n",
        "\n",
        "# â–¶ ë¹„ìœ¨ ê¸°ì¤€ìœ¼ë¡œ Split (train/val/test = 90/5/5)\n",
        "total_size = len(dataset)\n",
        "train_size = int(0.9 * total_size)\n",
        "val_size   = int(0.05 * total_size)\n",
        "test_size  = total_size - train_size - val_size\n",
        "\n",
        "print(f\"Total: {total_size}, Train: {train_size}, Val: {val_size}, Test: {test_size}\")\n",
        "\n",
        "train_dataset, val_dataset, test_dataset = random_split(\n",
        "    dataset, [train_size, val_size, test_size], generator=g\n",
        ")\n",
        "\n",
        "# â–¶ DataLoader ì •ì˜ (GPU í›ˆë ¨ ëŒ€ë¹„ `pin_memory=True` ê¶Œì¥)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,  num_workers=0, pin_memory=True, generator=g)\n",
        "val_loader   = DataLoader(val_dataset,   batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n",
        "test_loader  = DataLoader(test_dataset,  batch_size=batch_size, shuffle=False, pin_memory=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# (ì¶”ê°€) ì „ì²´ í•™ìŠµ ë°ì´í„°ë¥¼ Pandasë¡œ ì¶œë ¥í•˜ê¸°\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "# (1) ì—­ì •ê·œí™” thickness â†’ ì‹¤ì œ nmë¡œ ë³€í™˜\n",
        "d_real = destandardize_thickness(dataset.d_norm).cpu().numpy().squeeze()  # shape: (N, 3)\n",
        "\n",
        "# (2) spectrumì€ ì•„ì§ standardized ìƒíƒœì´ë¯€ë¡œ ë³µì›\n",
        "T_real = destandardize_spectrum(dataset.T_spec).cpu().numpy().squeeze()  # shape: (N, 401)\n",
        "\n",
        "# (3) Pandas DataFrameìœ¼ë¡œ ê²°í•©\n",
        "df_thickness = pd.DataFrame(d_real, columns=['d1_nm', 'd2_nm', 'd3_nm'])\n",
        "df_spectrum = pd.DataFrame(T_real, columns=[f\"T_{w}nm\" for w in WAVELENGTHS])\n",
        "\n",
        "# (4) ê²°í•©\n",
        "df_full = pd.concat([df_thickness, df_spectrum], axis=1)\n",
        "\n",
        "# (5) ìƒìœ„ 5ê°œ ìƒ˜í”Œ ì¶œë ¥\n",
        "print(df_full.head())\n",
        "\n",
        "# (6) ì „ì²´ ì €ì¥í•˜ê³  ì‹¶ë‹¤ë©´ (ì„ íƒ)\n",
        "df_full.to_csv(\"full_training_data.csv\", index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQlpr1VmBhIw",
        "outputId": "284af08d-d29f-4e7b-e6f9-6ddb2b3f336c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   d1_nm  d2_nm  d3_nm   T_380nm   T_381nm   T_382nm   T_383nm   T_384nm  \\\n",
            "0    5.0  150.0    5.0  0.664733  0.664586  0.664638  0.664841  0.665255   \n",
            "1    5.0  150.0   10.0  0.600258  0.601023  0.602018  0.603169  0.604548   \n",
            "2    5.0  150.0   15.0  0.521428  0.522529  0.523897  0.525447  0.527224   \n",
            "3    5.0  150.0   20.0  0.437933  0.438960  0.440282  0.441814  0.443557   \n",
            "4    5.0  150.0   25.0  0.357522  0.358260  0.359306  0.360578  0.362035   \n",
            "\n",
            "    T_385nm   T_386nm  ...   T_771nm   T_772nm   T_773nm   T_774nm   T_775nm  \\\n",
            "0  0.665836  0.666619  ...  0.531328  0.532044  0.532772  0.533509  0.534252   \n",
            "1  0.606091  0.607852  ...  0.410478  0.411625  0.412787  0.413959  0.415137   \n",
            "2  0.529156  0.531305  ...  0.292363  0.293426  0.294502  0.295586  0.296675   \n",
            "3  0.445438  0.447520  ...  0.199030  0.199842  0.200662  0.201487  0.202316   \n",
            "4  0.363610  0.365360  ...  0.132318  0.132886  0.133460  0.134037  0.134616   \n",
            "\n",
            "    T_776nm   T_777nm   T_778nm   T_779nm   T_780nm  \n",
            "0  0.535004  0.535765  0.536535  0.537314  0.538102  \n",
            "1  0.416326  0.417524  0.418733  0.419953  0.421182  \n",
            "2  0.297772  0.298878  0.299992  0.301115  0.302245  \n",
            "3  0.203151  0.203992  0.204838  0.205689  0.206547  \n",
            "4  0.135199  0.135785  0.136374  0.136967  0.137564  \n",
            "\n",
            "[5 rows x 404 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "LSaN4xqLJvjt",
        "outputId": "7a126304-5a26-4f70-f131-79719439f644"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[INFO] Start training InverseNet (best params)\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-46-2264318585.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m                             )\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"differentiable\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    242\u001b[0m             )\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m             adam(\n\u001b[0m\u001b[1;32m    245\u001b[0m                 \u001b[0mparams_with_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m                 \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mmaybe_fallback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mdisabled_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_fallback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    874\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_adam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 876\u001b[0;31m     func(\n\u001b[0m\u001b[1;32m    877\u001b[0m         \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    476\u001b[0m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 478\u001b[0;31m             \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m         \u001b[0;31m# Lastly, switch back to complex view\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import random_split, DataLoader\n",
        "import os\n",
        "\n",
        "# â–‘â–‘ 0. Seed ê³ ì • í•¨ìˆ˜ â–‘â–‘\n",
        "def seed_everything(seed: int = 42):\n",
        "    \"\"\"\n",
        "    ëª¨ë“  ë‚œìˆ˜ ìƒì„±ê¸°(random, numpy, torch)ì— ì‹œë“œë¥¼ ê³ ì •í•´\n",
        "    ì‹¤í—˜ ì¬í˜„ì„±ì„ ë³´ì¥í•¨. íŠ¹íˆ GPU ì—°ì‚°ì—ì„œë„ ìˆœì„œë¥¼ ê³ ì •í•˜ê¸° ìœ„í•´\n",
        "    cudnn ì˜µì…˜ë„ ì¡°ì •í•¨.\n",
        "    \"\"\"\n",
        "    import random, numpy as np\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "# â–‘â–‘ 1. ê³ ì • í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì • â–‘â–‘\n",
        "SEED = 42\n",
        "LR = 6.639623079859457e-05         # í•™ìŠµë¥ : ì˜µíŠœë‚˜ê°€ ì°¾ì€ ìµœì  ê°’\n",
        "ALPHA = 0.13940346079873228        # thickness lossì˜ ê°€ì¤‘ì¹˜ (joint loss)\n",
        "N_LAYERS = 4                       # MLP ì€ë‹‰ì¸µ ê°œìˆ˜\n",
        "N_UNITS = 768                      # ê° ì€ë‹‰ì¸µì˜ ë‰´ëŸ° ìˆ˜\n",
        "BATCH_SIZE = 32\n",
        "BETA = 14                          # thickness lossë¥¼ jointë¡œ í¬í•¨í•  ì—í­ ìˆ˜\n",
        "NUM_EPOCHS = 600                   # ì´ í•™ìŠµ epoch ìˆ˜\n",
        "SAVE_DIR = \"./checkpoints\"        # ëª¨ë¸ ì €ì¥ í´ë”\n",
        "SAVE_PATH = os.path.join(SAVE_DIR, \"inverse_best.pth\")  # ì €ì¥ ê²½ë¡œ\n",
        "\n",
        "# ë””ë ‰í† ë¦¬ ìƒì„± ë° ì‹œë“œ ê³ ì •\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "seed_everything(SEED)\n",
        "g = torch.Generator().manual_seed(SEED)\n",
        "\n",
        "# â–‘â–‘ 2. DataLoader êµ¬ì„± â–‘â–‘\n",
        "# ì‚¬ì „ ì •ì˜ëœ dataset / split ë¹„ìœ¨ ì‚¬ìš©\n",
        "train_dataset, val_dataset, _ = random_split(\n",
        "    dataset, [train_size, val_size, test_size], generator=g\n",
        ")\n",
        "\n",
        "# í•™ìŠµ/ê²€ì¦ìš© DataLoader ìƒì„±\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,  num_workers=0, generator=g)\n",
        "val_loader   = DataLoader(val_dataset,   batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
        "\n",
        "# â–‘â–‘ 3. InverseNet ì •ì˜ â–‘â–‘\n",
        "class InverseNet(nn.Module):\n",
        "    \"\"\"\n",
        "    ì…ë ¥: 401 í¬ì¸íŠ¸ì˜ ìŠ¤í™íŠ¸ëŸ¼ ë²¡í„°\n",
        "    ì¶œë ¥: ì •ê·œí™”ëœ ë‘ê»˜ ë²¡í„° [d1, d2, d3] âˆˆ [0, 1]\n",
        "    êµ¬ì¡°: [Linear â†’ LeakyReLU] Ã— N â†’ Linear â†’ Sigmoid\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim: int, output_dim: int, num_hidden_layers: int, units: int):\n",
        "        super().__init__()\n",
        "        layers = [nn.Linear(input_dim, units), nn.LeakyReLU()]  # ì²« ì¸µ\n",
        "        for _ in range(num_hidden_layers):\n",
        "            layers += [nn.Linear(units, units), nn.LeakyReLU()]  # ë°˜ë³µ ì€ë‹‰ì¸µ\n",
        "        layers += [nn.Linear(units, output_dim), nn.Sigmoid()]   # ì¶œë ¥ì¸µ\n",
        "        self.net = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "# ëª¨ë¸ ìƒì„± ë° GPU í• ë‹¹\n",
        "NUM_LAYERS_OUTPUT = len(material_sequence)  # ì˜ˆ: 3ì¸µ êµ¬ì¡°ë©´ 3\n",
        "inverse_net = InverseNet(\n",
        "    input_dim=NUM_WAVELENGTHS, output_dim=NUM_LAYERS_OUTPUT,\n",
        "    num_hidden_layers=N_LAYERS, units=N_UNITS\n",
        ").to(device).to(torch.float64)\n",
        "\n",
        "# ì˜µí‹°ë§ˆì´ì € ì •ì˜\n",
        "optimizer = optim.Adam(inverse_net.parameters(), lr=LR)\n",
        "\n",
        "# â–‘â–‘ 4. í•™ìŠµ ë£¨í”„ ì‹œì‘ â–‘â–‘\n",
        "print(\"\\n[INFO] Start training InverseNet (best params)\\n\")\n",
        "best_val_loss = float('inf')  # í˜„ì¬ê¹Œì§€ ê°€ì¥ ë‚®ì€ ê²€ì¦ ì†ì‹¤ ì €ì¥\n",
        "\n",
        "for epoch in range(1, NUM_EPOCHS + 1):\n",
        "\n",
        "    # (1) â–‘ í•™ìŠµ ë‹¨ê³„ â–‘\n",
        "    inverse_net.train()\n",
        "    epoch_loss = 0.0\n",
        "\n",
        "    for batch in train_loader:\n",
        "        T_target = batch['T_target'].to(device)        # ì •ê·œí™”ëœ ìŠ¤í™íŠ¸ëŸ¼ ì…ë ¥\n",
        "        d_norm_true = batch['d_norm'].to(device)       # ì •ê·œí™”ëœ ì •ë‹µ ë‘ê»˜\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        x = T_target.squeeze(1)                        # (B, 1, 401) â†’ (B, 401)\n",
        "        d_norm_pred = inverse_net(x)                  # ì •ê·œí™”ëœ ë‘ê»˜ ì˜ˆì¸¡ (B, 3)\n",
        "\n",
        "        # ì˜ˆì¸¡ëœ ë‘ê»˜ â†’ ë¹„ì •ê·œí™”(nm ë‹¨ìœ„)\n",
        "        d_nm_pred = destandardize_thickness(d_norm_pred)  # (B, 3)\n",
        "\n",
        "        # forward TMM ëª¨ë¸ë¡œ ìŠ¤í™íŠ¸ëŸ¼ ì˜ˆì¸¡\n",
        "        T_pred_batch = model(d_nm_pred)               # (B, 401)\n",
        "\n",
        "        # ì…ë ¥ ìŠ¤í™íŠ¸ëŸ¼ (ì •ê·œí™”ëœ x)ë„ ì—­ì •ê·œí™”\n",
        "        T_target_destd = destandardize_spectrum(x)    # (B, 401)\n",
        "\n",
        "        # (a) spectrum loss (ì—­ì •ê·œí™”ëœ T ê¸°ì¤€)\n",
        "        loss_spectrum = F.mse_loss(T_pred_batch, T_target_destd)\n",
        "\n",
        "        # (b) thickness loss (ì •ê·œí™” ìƒíƒœì—ì„œ ì§ì ‘ ë¹„êµ)\n",
        "        loss_thickness = F.mse_loss(d_norm_pred, d_norm_true.squeeze(1))\n",
        "\n",
        "        # (c) epochì— ë”°ë¼ joint loss vs spectrum only\n",
        "        if epoch <= BETA:\n",
        "            loss = loss_spectrum + ALPHA * loss_thickness\n",
        "        else:\n",
        "            loss = loss_spectrum\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    # (2) â–‘ ê²€ì¦ ë‹¨ê³„ â–‘\n",
        "    inverse_net.eval()\n",
        "    val_loss_total = 0.0\n",
        "    with torch.no_grad():\n",
        "        for val_batch in val_loader:\n",
        "            T_val = val_batch['T_target'].to(device)\n",
        "            d_norm_val = val_batch['d_norm'].to(device)\n",
        "\n",
        "            x_val = T_val.squeeze(1).to(torch.float64)\n",
        "            d_pred_val = inverse_net(x_val)\n",
        "            d_nm_val_pred = destandardize_thickness(d_pred_val)\n",
        "            T_val_pred = model(d_nm_val_pred)\n",
        "            T_val_destd = destandardize_spectrum(x_val)\n",
        "\n",
        "            loss_spectrum_v = F.mse_loss(T_val_pred, T_val_destd)\n",
        "            loss_thickness_v = F.mse_loss(d_pred_val, d_norm_val.squeeze(1))\n",
        "            val_loss = (loss_spectrum_v + ALPHA * loss_thickness_v) if epoch <= BETA else loss_spectrum_v\n",
        "            val_loss_total += val_loss.item()\n",
        "\n",
        "    # (3) â–‘ ë¡œê·¸ ì¶œë ¥ + Best ëª¨ë¸ ì €ì¥ â–‘\n",
        "    avg_train_loss = epoch_loss / len(train_loader)\n",
        "    avg_val_loss = val_loss_total / len(val_loader)\n",
        "\n",
        "    print(f\"Epoch[{epoch}/{NUM_EPOCHS}]  train: {avg_train_loss:.6f}  val: {avg_val_loss:.6f}\")\n",
        "\n",
        "    if avg_val_loss < best_val_loss:\n",
        "        best_val_loss = avg_val_loss\n",
        "        torch.save(inverse_net.state_dict(), SAVE_PATH)  # ê°€ì¥ ì¢‹ì€ ëª¨ë¸ ì €ì¥\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfUbpAta08jg"
      },
      "source": [
        "# **í•™ìŠµ ì‹œí‚¨ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-LujPwH0t6Y",
        "outputId": "7db0c0a3-d997-42b5-adfc-18074097f888"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… ëª¨ë¸ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì„±ê³µ\n",
            "âœ… ëª¨ë¸ íŒŒë¼ë¯¸í„° ë¡œë“œ ì„±ê³µ\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import urllib.request\n",
        "import os\n",
        "\n",
        "# â–‘â–‘ ëª¨ë¸ ì •ì˜ â–‘â–‘\n",
        "class InverseNet(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, 768), nn.LeakyReLU(),\n",
        "            nn.Linear(768, 768), nn.LeakyReLU(),\n",
        "            nn.Linear(768, 768), nn.LeakyReLU(),\n",
        "            nn.Linear(768, 768), nn.LeakyReLU(),\n",
        "            nn.Linear(768, 768), nn.LeakyReLU(),\n",
        "            nn.Linear(768, output_dim), nn.Sigmoid()\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "# â–‘â–‘ ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ â–‘â–‘\n",
        "inverse_net = InverseNet(input_dim=NUM_WAVELENGTHS, output_dim=len(material_sequence)).to(device).to(torch.float64)\n",
        "\n",
        "# â–‘â–‘ GitHubì—ì„œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ â–‘â–‘\n",
        "github_url = \"https://raw.githubusercontent.com/KIMEUIJOON-KNU/Bi-directional/main/inverse_best_New.pth\"\n",
        "local_model_path = \"inverse_best_New.pth\"\n",
        "\n",
        "try:\n",
        "    urllib.request.urlretrieve(github_url, local_model_path)\n",
        "    print(\"âœ… ëª¨ë¸ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì„±ê³µ\")\n",
        "except Exception as e:\n",
        "    print(\"âŒ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨:\", e)\n",
        "\n",
        "# â–‘â–‘ ëª¨ë¸ íŒŒë¼ë¯¸í„° ë¡œë“œ â–‘â–‘\n",
        "try:\n",
        "    inverse_net.load_state_dict(torch.load(local_model_path, map_location=device))\n",
        "    print(\"âœ… ëª¨ë¸ íŒŒë¼ë¯¸í„° ë¡œë“œ ì„±ê³µ\")\n",
        "except Exception as e:\n",
        "    print(\"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨:\", e)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import urllib.request\n",
        "import os\n",
        "\n",
        "# â–‘â–‘ ëª¨ë¸ ì •ì˜ â–‘â–‘\n",
        "class InverseNet(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, 768), nn.LeakyReLU(),\n",
        "            nn.Linear(768, 768), nn.LeakyReLU(),\n",
        "            nn.Linear(768, 768), nn.LeakyReLU(),\n",
        "            nn.Linear(768, 768), nn.LeakyReLU(),\n",
        "            nn.Linear(768, 768), nn.LeakyReLU(),\n",
        "            nn.Linear(768, output_dim), nn.Sigmoid()\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "# â–‘â–‘ ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ â–‘â–‘\n",
        "inverse_net = InverseNet(input_dim=NUM_WAVELENGTHS, output_dim=len(material_sequence)).to(device).to(torch.float64)\n",
        "\n",
        "# â–‘â–‘ GitHubì—ì„œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ â–‘â–‘\n",
        "github_url = \"https://raw.githubusercontent.com/KIMEUIJOON-KNU/Bi-directional/main/inverse_best_New.pth\"\n",
        "local_model_path = \"inverse_best_New.pth\"\n",
        "\n",
        "try:\n",
        "    urllib.request.urlretrieve(github_url, local_model_path)\n",
        "    print(\"âœ… ëª¨ë¸ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì„±ê³µ\")\n",
        "except Exception as e:\n",
        "    print(\"âŒ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨:\", e)\n",
        "\n",
        "# â–‘â–‘ ëª¨ë¸ íŒŒë¼ë¯¸í„° ë¡œë“œ â–‘â–‘\n",
        "try:\n",
        "    inverse_net.load_state_dict(torch.load(local_model_path, map_location=device))\n",
        "    print(\"âœ… ëª¨ë¸ íŒŒë¼ë¯¸í„° ë¡œë“œ ì„±ê³µ\")\n",
        "except Exception as e:\n",
        "    print(\"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨:\", e)\n",
        "\n",
        "# â–‘â–‘ (4) test setë§Œ ì¶”ì¶œ â–‘â–‘\n",
        "_, _, test_dataset = random_split(dataset, [train_size, val_size, test_size], generator=torch.Generator().manual_seed(42))\n",
        "\n",
        "# â–‘â–‘ (5) ì˜ˆì¸¡ ì‹¤í–‰ (ì „ì²´ test set) â–‘â–‘\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "all_true_d = []\n",
        "all_pred_d = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        T_test = batch['T_target'].to(device).squeeze(1)\n",
        "        d_true_norm = batch['d_norm'].to(device)\n",
        "\n",
        "        # ì˜ˆì¸¡ (ì •ê·œí™”ëœ ë‘ê»˜)\n",
        "        d_pred_norm = inverse_net(T_test)\n",
        "\n",
        "        # ì •ê·œí™”ëœ ë‘ê»˜ â†’ ì‹¤ì œ ë‘ê»˜(nm)\n",
        "        d_pred_nm = destandardize_thickness(d_pred_norm).cpu().numpy()\n",
        "        d_true_nm = destandardize_thickness(d_true_norm).cpu().numpy()\n",
        "\n",
        "        all_true_d.append(d_true_nm)\n",
        "        all_pred_d.append(d_pred_nm)\n",
        "\n",
        "# â–‘â–‘ (6) ê²°ê³¼ ë³‘í•© ë° DataFrame ì¶œë ¥ â–‘â–‘\n",
        "true_all = torch.tensor(np.concatenate(all_true_d, axis=0))\n",
        "pred_all = torch.tensor(np.concatenate(all_pred_d, axis=0))\n",
        "\n",
        "df_result = pd.DataFrame({\n",
        "    \"True_d1\": true_all[:, 0],\n",
        "    \"True_d2\": true_all[:, 1],\n",
        "    \"True_d3\": true_all[:, 2],\n",
        "    \"Pred_d1\": pred_all[:, 0],\n",
        "    \"Pred_d2\": pred_all[:, 1],\n",
        "    \"Pred_d3\": pred_all[:, 2],\n",
        "})\n",
        "\n",
        "print(df_result.head(10))  # ìƒìœ„ 10ê°œ ê²°ê³¼ ì¶œë ¥\n",
        "excel_path = \"inverse_test_result.xlsx\"\n",
        "df_result.to_excel(excel_path, index=False)\n",
        "print(f\"ì €ì¥ ì™„ë£Œ: {excel_path}\")"
      ],
      "metadata": {
        "id": "u3x6cGaVGb0O",
        "outputId": "18ff5f60-8198-4da5-c39a-f5911168cc87",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… ëª¨ë¸ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì„±ê³µ\n",
            "âœ… ëª¨ë¸ íŒŒë¼ë¯¸í„° ë¡œë“œ ì„±ê³µ\n",
            "   True_d1  True_d2  True_d3    Pred_d1     Pred_d2    Pred_d3\n",
            "0     15.0    430.0     20.0  14.825414  429.895890  20.286923\n",
            "1     25.0    685.0     30.0  25.737539  684.942827  29.671310\n",
            "2     10.0    485.0      5.0   8.254471  486.948506   6.991958\n",
            "3     15.0    630.0     40.0  15.063486  630.098762  39.918744\n",
            "4     15.0    385.0     25.0  14.593657  384.706214  25.016640\n",
            "5     10.0    440.0     20.0   9.734059  439.415833  20.101497\n",
            "6     40.0    615.0     35.0  36.105777  615.054982  37.982515\n",
            "7     30.0    285.0      5.0   7.685507  294.291328  26.966713\n",
            "8     25.0    220.0     30.0  25.216201  219.926069  29.712750\n",
            "9     30.0    420.0     30.0  29.973181  419.944812  29.953681\n",
            "ì €ì¥ ì™„ë£Œ: inverse_test_result.xlsx\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}