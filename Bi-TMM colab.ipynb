{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OKdr0AFPWE7x"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **굴절률 데이터 가져오기 (TMM으로 데이터 생성시 필요)**"
      ],
      "metadata": {
        "id": "YVRJZWbMCPFP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6wcpY_qWA9B",
        "outputId": "3639700e-c808-492e-c82f-5f63f061f40d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "재료 리스트: ['SiO2', 'WO3', 'Ag']\n",
            "재료 인덱스 매핑: {0: 'Ag', 1: 'SiO2', 2: 'WO3'}\n",
            "처리 중: SiO2_380.csv (materials: SiO2) → https://raw.githubusercontent.com/KIMEUIJOON-KNU/Bi-directional/main/SiO2_380.csv\n",
            "로드 완료: 401 points\n",
            "처리 중: WO3_380.csv (materials: WO3) → https://raw.githubusercontent.com/KIMEUIJOON-KNU/Bi-directional/main/WO3_380.csv\n",
            "로드 완료: 401 points\n",
            "처리 중: Ag_380.csv (materials: Ag) → https://raw.githubusercontent.com/KIMEUIJOON-KNU/Bi-directional/main/Ag_380.csv\n",
            "로드 완료: 401 points\n",
            "Air 굴절률 추가 완료\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# 파장 정의\n",
        "WAVELENGTHS = np.arange(380, 781, 1)\n",
        "NUM_WAVELENGTHS = len(WAVELENGTHS) #401\n",
        "\n",
        "# GitHub raw 주소 (파일들이 위치한 경로)\n",
        "base_url = \"https://raw.githubusercontent.com/KIMEUIJOON-KNU/Bi-directional/main/\"\n",
        "\n",
        "# 사용할 재료 목록\n",
        "material_files = [\n",
        "    ('SiO2', 'SiO2_380.csv'),\n",
        "    ('WO3',  'WO3_380.csv'),\n",
        "    ('Ag',   'Ag_380.csv')\n",
        "]\n",
        "\n",
        "material_data = {}\n",
        "material_names = [info[0] for info in material_files]\n",
        "print(\"재료 리스트:\", material_names)\n",
        "\n",
        "# 재료 인덱싱 매핑\n",
        "material_names = sorted(set(material_names))\n",
        "material_to_index = {name: i for i, name in enumerate(material_names)}\n",
        "index_to_material = {i: name for name, i in material_to_index.items()}\n",
        "print(\"재료 인덱스 매핑:\", index_to_material)\n",
        "\n",
        "# --- 재료 파일 불러오기 ---\n",
        "for material_name, filename in material_files:\n",
        "    file_url = base_url + filename\n",
        "    print(f\"처리 중: {filename} (materials: {material_name}) → {file_url}\")\n",
        "    try:\n",
        "        data = pd.read_csv(file_url, header=None)\n",
        "    except Exception as e:\n",
        "        print(f\"  🚫 오류 발생: {e}\")\n",
        "        continue\n",
        "\n",
        "    if data.empty:\n",
        "        print(\"  ⚠️ 경고: 파일이 비어있습니다.\")\n",
        "        continue\n",
        "\n",
        "    wavelengths = data.iloc[:, 0].values  # 파장\n",
        "    n = data.iloc[:, 1].values           # 실수부\n",
        "    k = data.iloc[:, 2].values           # 허수부\n",
        "\n",
        "    n_complex = n + 1j * k               # 복소 굴절률\n",
        "\n",
        "    material_data[material_name] = (wavelengths, n_complex)\n",
        "    print(f\"로드 완료: {len(wavelengths)} points\")\n",
        "\n",
        "# --- 공기 굴절률 추가 ---\n",
        "material_data['Air'] = np.ones(NUM_WAVELENGTHS, dtype=np.complex128)\n",
        "print(\"Air 굴절률 추가 완료\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xyfqaeLeBLec",
        "outputId": "a9069be9-3b78-41f8-a2b5-cc71349d4d2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8384\n"
          ]
        }
      ],
      "source": [
        "# ────────────────────────────────────────────────────────────────────────────\n",
        "# (1) 파장 정의 (380~780 nm, 1 nm 간격 → 총 401개 파장 지점)\n",
        "# ────────────────────────────────────────────────────────────────────────────\n",
        "λ_tensor_global = torch.tensor(WAVELENGTHS, dtype=torch.float64).to(device) * 1e-9  # [m 단위로 변환된 파장 텐서]\n",
        "\n",
        "# ────────────────────────────────────────────────────────────────────────────\n",
        "# (2) 층별 재료 정의 (MIM 구조 예시: 금속-절연체-금속)\n",
        "# ────────────────────────────────────────────────────────────────────────────\n",
        "material_sequence = ['Ag', 'WO3', 'Ag']  # 구조에 사용될 재료 순서 (입사면에서부터 아래 방향)\n",
        "\n",
        "# material_data 에서 각 재료의 복소 굴절률 (n + ik) 값 추출 (shape: [401])\n",
        "n_list_np_arrays = [material_data[mat][1] for mat in material_sequence]  # 길이 3 리스트 (각각 [401] 크기)\n",
        "\n",
        "# numpy → torch 변환 후, complex64 형식으로 묶어서 GPU로 이동 (shape: [3, 401])\n",
        "n_list_torch = torch.stack([\n",
        "    torch.from_numpy(arr).to(torch.complex64) for arr in n_list_np_arrays\n",
        "], dim=0).to(device)\n",
        "\n",
        "# ────────────────────────────────────────────────────────────────────────────\n",
        "# (3) 입사 매질 (n_i)와 출사 매질 (n_s) 설정\n",
        "# ────────────────────────────────────────────────────────────────────────────\n",
        "n_i_np = material_data['SiO2'][1]   # 입사 매질: SiO2의 복소 굴절률 (n + ik)\n",
        "n_s_np = material_data['Air']       # 출사 매질: Air (n=1, k=0)\n",
        "\n",
        "n_i_torch = torch.from_numpy(n_i_np).to(torch.complex64).to(device)  # torch 변환 후 GPU 이동\n",
        "n_s_torch = torch.from_numpy(n_s_np).to(torch.complex64).to(device)\n",
        "\n",
        "# ────────────────────────────────────────────────────────────────────────────\n",
        "# (4) 두께 그리드 정의 (nm 단위, 총 조합 수 = 8 * 187 * 8 = 11968개)\n",
        "# ────────────────────────────────────────────────────────────────────────────\n",
        "d1_list_nm = np.arange(5, 41, 5)      # 금속층 (d1): 5 ~ 40 nm, 간격 5 nm → 총 8개\n",
        "d2_list_nm = np.arange(150, 801, 5)    # 절연층 (d2): 20 ~ 950 nm, 간격 5 nm → 총 187개\n",
        "d3_list_nm = np.arange(5, 41, 5)      # 금속층 (d3): 5 ~ 40 nm, 간격 5 nm → 총 8개\n",
        "\n",
        "print(len(d1_list_nm)*len(d2_list_nm)*len(d3_list_nm))  # 총 조합 개수 출력 (8 × 187 × 8 = 11,968)\n",
        "\n",
        "# ────────────────────────────────────────────────────────────────────────────\n",
        "# (5) 샘플 저장용 리스트 초기화\n",
        "# ────────────────────────────────────────────────────────────────────────────\n",
        "\n",
        "all_d_tilde = []    # ▶ 각 샘플의 (d1, d2, d3) 두께 조합을 저장할 리스트\n",
        "                    #   일반적으로 나중에 정규화된 형태로 저장되며 학습 입력으로 사용\n",
        "\n",
        "all_T_target = []   # ▶ 각 조합에 대응하는 스펙트럼 T(λ) [shape: (401,)] 를 저장할 리스트\n",
        "                    #   Forward model을 통해 계산된 정답 스펙트럼 (target)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hnFyPOo-v2xi"
      },
      "outputs": [],
      "source": [
        "# ────────────────────────────────────────────────────────────────────────────\n",
        "# (A-1) TMMNetwork 정의 (클래스 이름, dtype 통일, calculate() 추가)\n",
        "# ────────────────────────────────────────────────────────────────────────────\n",
        "class TMMNetwork(nn.Module):\n",
        "    def __init__(self, n_list_input, n_i_input, n_s_input, wavelengths_m_tensor):\n",
        "        super().__init__()\n",
        "        dtype_complex = torch.complex128\n",
        "        dtype_float = torch.float64\n",
        "\n",
        "        n_list_real = n_list_input.real\n",
        "        n_list_imag = -torch.abs(n_list_input.imag)\n",
        "        self.register_buffer('n_list', torch.complex(n_list_real, n_list_imag))\n",
        "        self.register_buffer('n_i', n_i_input.to(dtype_complex))\n",
        "        self.register_buffer('n_s', n_s_input.to(dtype_complex))\n",
        "\n",
        "        # 파수 k0\n",
        "        k0 = 2 * torch.pi / torch.clamp(wavelengths_m_tensor, min=1e-20)\n",
        "        self.register_buffer('k0', k0)  # 이제 k0_tilde 아님\n",
        "\n",
        "        self.num_layers = self.n_list.shape[0]\n",
        "        self.num_wavelengths = wavelengths_m_tensor.shape[0]\n",
        "\n",
        "    def forward(self, thicknesses_nm):\n",
        "        device = thicknesses_nm.device\n",
        "        dtype_complex = torch.complex128\n",
        "        imag_unit = torch.tensor(1j, dtype=dtype_complex, device=device)\n",
        "\n",
        "        if thicknesses_nm.ndim == 1:\n",
        "            thicknesses_nm = thicknesses_nm.unsqueeze(0)  # (1, 3)\n",
        "        B = thicknesses_nm.shape[0]  # batch size\n",
        "\n",
        "        # Convert to meters\n",
        "        thicknesses_m = thicknesses_nm * 1e-9  # (B, 3)\n",
        "\n",
        "        # (B, 3, 401): broadcasting layer × wavelength\n",
        "        delta = thicknesses_m[:, :, None] * self.k0[None, None, :] * self.n_list[None, :, :]\n",
        "\n",
        "        cosδ = torch.cos(delta)\n",
        "        sinδ = torch.sin(delta)\n",
        "\n",
        "        # 초기 M_total: (B, 401, 2, 2)\n",
        "        M_total = torch.eye(2, dtype=dtype_complex, device=device).repeat(B, self.num_wavelengths, 1, 1)\n",
        "\n",
        "        for j in range(self.num_layers):\n",
        "            Yj = self.n_list[j] * 2.654e-3  # (401,)\n",
        "\n",
        "            sin_j = sinδ[:, j, :]\n",
        "            cos_j = cosδ[:, j, :]\n",
        "\n",
        "            m11 = cos_j\n",
        "            m12 = imag_unit * sin_j / Yj[None, :]\n",
        "            m21 = imag_unit * Yj[None, :] * sin_j\n",
        "            m22 = cos_j\n",
        "\n",
        "            Mj = torch.stack([\n",
        "                torch.stack([m11, m12], dim=-1),\n",
        "                torch.stack([m21, m22], dim=-1)\n",
        "            ], dim=-2)  # shape: (B, 401, 2, 2)\n",
        "\n",
        "            M_total = torch.matmul(M_total, Mj)\n",
        "\n",
        "        Y_in = self.n_i * 2.654e-3\n",
        "        Y_out = self.n_s * 2.654e-3\n",
        "\n",
        "        B_ = M_total[:, :, 0, 0] + M_total[:, :, 0, 1] * Y_out\n",
        "        C_ = M_total[:, :, 1, 0] + M_total[:, :, 1, 1] * Y_out\n",
        "        denom = Y_in * B_ + C_\n",
        "        t1 = (2 * Y_in) / denom  # (B, 401)\n",
        "\n",
        "        T = (torch.real(self.n_s) / torch.real(self.n_i)) * torch.abs(t1) ** 2\n",
        "        return T.to(torch.float64)  # (B, 401)\n",
        "\n",
        "model = TMMNetwork(n_list_torch, n_i_torch, n_s_torch, λ_tensor_global).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "awPhXGk1CHwC"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# ------------------------------\n",
        "# 시드 고정 (재현성 확보)\n",
        "# ------------------------------\n",
        "def seed_everything(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)  # if using multi-GPU\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "seed_everything(42)  # 시드 고정 실행"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QB5wv5A3j8H",
        "outputId": "eaa3e2f7-a707-4b40-d855-1a98b2992ff9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating (normalized_d → T_target) pairs ...\n",
            "Total samples: 8384\n",
            "Total: 8384, Train: 7545, Val: 419, Test: 420\n"
          ]
        }
      ],
      "source": [
        "# ──────────────────────────────────────────────\n",
        "# (A) 데이터 생성: (두께 → 스펙트럼) via TMM\n",
        "# ──────────────────────────────────────────────\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "\n",
        "all_d = []           # ▶ 각 샘플의 [d1, d2, d3] 두께 조합 (정규화 전, nm)\n",
        "all_T_target = []    # ▶ 각 샘플에 대한 T(λ) 스펙트럼 (shape: [401])\n",
        "\n",
        "print(\"Generating (normalized_d → T_target) pairs ...\")\n",
        "\n",
        "for d1 in d1_list_nm:\n",
        "    for d2 in d2_list_nm:\n",
        "        for d3 in d3_list_nm:\n",
        "            d_nm_vec = torch.tensor([[d1, d2, d3]], dtype=torch.float64)  # shape: [1, 3]\n",
        "            all_d.append(d_nm_vec.cpu().numpy().squeeze(0))  # shape: [3]\n",
        "\n",
        "            T_spec = model(d_nm_vec.to(device))              # TMM forward (입력: nm 단위 두께)\n",
        "            all_T_target.append(T_spec.detach().cpu().numpy())\n",
        "\n",
        "# ▶ NumPy 배열로 변환 (shape: [N, 3] / [N, 401])\n",
        "all_d = np.array(all_d, dtype=np.float64)\n",
        "all_T_target = np.array(all_T_target, dtype=np.float64)\n",
        "print(\"Total samples:\", all_d.shape[0])\n",
        "\n",
        "# ──────────────────────────────────────────────\n",
        "# (B) 두께 정규화 (Min-Max Scaling)\n",
        "# ──────────────────────────────────────────────\n",
        "THICKNESS_MIN = torch.tensor(np.min(all_d, axis=0), dtype=torch.float64, device=device)\n",
        "THICKNESS_MAX = torch.tensor(np.max(all_d, axis=0), dtype=torch.float64, device=device)\n",
        "\n",
        "def standardize_thickness(d_nm_array):\n",
        "    \"\"\"입력: 실제 두께 (nm), 출력: 정규화된 두께 [0,1]\"\"\"\n",
        "    d_nm_array = torch.tensor(d_nm_array, dtype=torch.float64, device=device) if not isinstance(d_nm_array, torch.Tensor) else d_nm_array.to(dtype=torch.float64, device=device)\n",
        "    return (d_nm_array - THICKNESS_MIN) / (THICKNESS_MAX - THICKNESS_MIN)\n",
        "\n",
        "def destandardize_thickness(d_norm_array):\n",
        "    \"\"\"입력: 정규화된 두께, 출력: 실제 두께 (nm)\"\"\"\n",
        "    d_norm_array = d_norm_array.clone().to(dtype=torch.float64, device=device)\n",
        "    return d_norm_array * (THICKNESS_MAX - THICKNESS_MIN) + THICKNESS_MIN\n",
        "\n",
        "all_d_norm = standardize_thickness(all_d)                     # shape: [N, 3]\n",
        "d_nm_check = destandardize_thickness(all_d_norm)              # 역변환 확인용\n",
        "\n",
        "# ──────────────────────────────────────────────\n",
        "# (C) 스펙트럼 정규화 (Min-Max Scaling per λ)\n",
        "# ──────────────────────────────────────────────\n",
        "SPECTRUM_MIN = torch.tensor(np.min(all_T_target, axis=0), dtype=torch.float64).to(device)\n",
        "SPECTRUM_MAX = torch.tensor(np.max(all_T_target, axis=0), dtype=torch.float64).to(device)\n",
        "\n",
        "def standardize_spectrum(T_array):\n",
        "    \"\"\"입력: 원본 스펙트럼, 출력: [0,1] 정규화\"\"\"\n",
        "    T_tensor = torch.tensor(T_array, dtype=torch.float64).to(device)\n",
        "    return (T_tensor - SPECTRUM_MIN) / (SPECTRUM_MAX - SPECTRUM_MIN)\n",
        "\n",
        "def destandardize_spectrum(T_std_array):\n",
        "    \"\"\"입력: 정규화된 스펙트럼, 출력: 원본 스펙트럼\"\"\"\n",
        "    return T_std_array * (SPECTRUM_MAX - SPECTRUM_MIN) + SPECTRUM_MIN\n",
        "\n",
        "# ▶ 정규화 적용 + 역변환 체크\n",
        "all_T_target_std = standardize_spectrum(all_T_target)\n",
        "restored_T = destandardize_spectrum(all_T_target_std)\n",
        "assert np.allclose(restored_T.cpu().numpy(), all_T_target, atol=1e-5)\n",
        "\n",
        "# ──────────────────────────────────────────────\n",
        "# (D) PyTorch Dataset 정의\n",
        "# ──────────────────────────────────────────────\n",
        "class BiTMMNormalizedDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Bi-directional TMM용 데이터셋 클래스.\n",
        "    입력: 정규화된 두께\n",
        "    출력: 정규화된 스펙트럼\n",
        "    \"\"\"\n",
        "    def __init__(self, d_norm_array, T_array):\n",
        "        self.d_norm = d_norm_array.clone().to(dtype=torch.float64)\n",
        "        self.T_spec = T_array.clone().detach().to(dtype=torch.float64) if isinstance(T_array, torch.Tensor) else torch.tensor(T_array, dtype=torch.float64)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.d_norm.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            'd_norm': self.d_norm[idx],       # shape: [3]\n",
        "            'T_target': self.T_spec[idx]      # shape: [401]\n",
        "        }\n",
        "\n",
        "# ──────────────────────────────────────────────\n",
        "# (E) Dataset 분할 및 DataLoader 구성\n",
        "# ──────────────────────────────────────────────\n",
        "batch_size = 32\n",
        "seed = 42\n",
        "g = torch.Generator().manual_seed(seed)  # 시드 고정\n",
        "\n",
        "# ▶ 전체 Dataset 생성\n",
        "dataset = BiTMMNormalizedDataset(all_d_norm, all_T_target_std)\n",
        "\n",
        "# ▶ 비율 기준으로 Split (train/val/test = 90/5/5)\n",
        "total_size = len(dataset)\n",
        "train_size = int(0.9 * total_size)\n",
        "val_size   = int(0.05 * total_size)\n",
        "test_size  = total_size - train_size - val_size\n",
        "\n",
        "print(f\"Total: {total_size}, Train: {train_size}, Val: {val_size}, Test: {test_size}\")\n",
        "\n",
        "train_dataset, val_dataset, test_dataset = random_split(\n",
        "    dataset, [train_size, val_size, test_size], generator=g\n",
        ")\n",
        "\n",
        "# ▶ DataLoader 정의 (GPU 훈련 대비 `pin_memory=True` 권장)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,  num_workers=0, pin_memory=True, generator=g)\n",
        "val_loader   = DataLoader(val_dataset,   batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n",
        "test_loader  = DataLoader(test_dataset,  batch_size=batch_size, shuffle=False, pin_memory=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ──────────────────────────────────────────────\n",
        "# (추가) 전체 학습 데이터를 Pandas로 출력하기\n",
        "# ──────────────────────────────────────────────\n",
        "\n",
        "# (1) 역정규화 thickness → 실제 nm로 변환\n",
        "d_real = destandardize_thickness(dataset.d_norm).cpu().numpy().squeeze()  # shape: (N, 3)\n",
        "\n",
        "# (2) spectrum은 아직 standardized 상태이므로 복원\n",
        "T_real = destandardize_spectrum(dataset.T_spec).cpu().numpy().squeeze()  # shape: (N, 401)\n",
        "\n",
        "# (3) Pandas DataFrame으로 결합\n",
        "df_thickness = pd.DataFrame(d_real, columns=['d1_nm', 'd2_nm', 'd3_nm'])\n",
        "df_spectrum = pd.DataFrame(T_real, columns=[f\"T_{w}nm\" for w in WAVELENGTHS])\n",
        "\n",
        "# (4) 결합\n",
        "df_full = pd.concat([df_thickness, df_spectrum], axis=1)\n",
        "\n",
        "# (5) 상위 5개 샘플 출력\n",
        "print(df_full.head())\n",
        "\n",
        "# (6) 전체 저장하고 싶다면 (선택)\n",
        "df_full.to_csv(\"full_training_data.csv\", index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQlpr1VmBhIw",
        "outputId": "284af08d-d29f-4e7b-e6f9-6ddb2b3f336c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   d1_nm  d2_nm  d3_nm   T_380nm   T_381nm   T_382nm   T_383nm   T_384nm  \\\n",
            "0    5.0  150.0    5.0  0.664733  0.664586  0.664638  0.664841  0.665255   \n",
            "1    5.0  150.0   10.0  0.600258  0.601023  0.602018  0.603169  0.604548   \n",
            "2    5.0  150.0   15.0  0.521428  0.522529  0.523897  0.525447  0.527224   \n",
            "3    5.0  150.0   20.0  0.437933  0.438960  0.440282  0.441814  0.443557   \n",
            "4    5.0  150.0   25.0  0.357522  0.358260  0.359306  0.360578  0.362035   \n",
            "\n",
            "    T_385nm   T_386nm  ...   T_771nm   T_772nm   T_773nm   T_774nm   T_775nm  \\\n",
            "0  0.665836  0.666619  ...  0.531328  0.532044  0.532772  0.533509  0.534252   \n",
            "1  0.606091  0.607852  ...  0.410478  0.411625  0.412787  0.413959  0.415137   \n",
            "2  0.529156  0.531305  ...  0.292363  0.293426  0.294502  0.295586  0.296675   \n",
            "3  0.445438  0.447520  ...  0.199030  0.199842  0.200662  0.201487  0.202316   \n",
            "4  0.363610  0.365360  ...  0.132318  0.132886  0.133460  0.134037  0.134616   \n",
            "\n",
            "    T_776nm   T_777nm   T_778nm   T_779nm   T_780nm  \n",
            "0  0.535004  0.535765  0.536535  0.537314  0.538102  \n",
            "1  0.416326  0.417524  0.418733  0.419953  0.421182  \n",
            "2  0.297772  0.298878  0.299992  0.301115  0.302245  \n",
            "3  0.203151  0.203992  0.204838  0.205689  0.206547  \n",
            "4  0.135199  0.135785  0.136374  0.136967  0.137564  \n",
            "\n",
            "[5 rows x 404 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "LSaN4xqLJvjt",
        "outputId": "c69966df-820f-49a8-aa1d-b46a53ee5de3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[INFO] Start training InverseNet (best params)\n",
            "\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'trial' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-13-2246638820.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0mbest_val_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'inf'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 가장 큰 값으로 초기화\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m \u001b[0mepoch_pbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_EPOCHS\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"Trial {trial.number}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_EPOCHS\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;31m# ---- train ----\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'trial' is not defined"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import random_split, DataLoader\n",
        "import os\n",
        "\n",
        "# ░░ 0. Seed 고정 함수 ░░\n",
        "def seed_everything(seed: int = 42):\n",
        "    \"\"\"학습 재현성을 위한 시드 고정 (random, numpy, torch 등)\"\"\"\n",
        "    import random, numpy as np\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True  # 연산 순서 고정\n",
        "    torch.backends.cudnn.benchmark = False     # 최적화 탐색 OFF (재현성 위해)\n",
        "\n",
        "# ░░ 1. 고정 하이퍼파라미터\n",
        "SEED = 42\n",
        "LR = 6.639623079859457e-05         # 학습률 (Optuna에서 찾은 best value)\n",
        "ALPHA = 0.13940346079873228        # 두께 예측 loss의 가중치 (Joint loss에서 사용)\n",
        "N_LAYERS = 4                       # InverseNet의 은닉층 개수\n",
        "N_UNITS = 768                      # 각 은닉층의 뉴런 수\n",
        "BATCH_SIZE = 32\n",
        "BETA = 14                          # Joint loss 사용 기간 (epoch <= BETA일 때만)\n",
        "NUM_EPOCHS = 600\n",
        "SAVE_DIR = \"./checkpoints\"\n",
        "SAVE_PATH = os.path.join(SAVE_DIR, \"inverse_best.pth\")\n",
        "\n",
        "# 폴더 생성 및 시드 고정\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "seed_everything(SEED)\n",
        "g = torch.Generator().manual_seed(SEED)\n",
        "\n",
        "# ░░ 2. DataLoader 구성 ░░\n",
        "# dataset, train_size, val_size, test_size는 이미 사전 정의돼 있어야 함\n",
        "train_dataset, val_dataset, _ = random_split(dataset, [train_size, val_size, test_size], generator=g)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0, generator=g)\n",
        "val_loader   = DataLoader(val_dataset,   batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
        "\n",
        "# ░░ 3. InverseNet 정의 ░░\n",
        "class InverseNet(nn.Module):\n",
        "    \"\"\"\n",
        "    입력: 스펙트럼 (401차원) → 출력: 정규화된 두께 벡터 (3차원)\n",
        "    MLP 구조: [Linear → LeakyReLU] × N → Linear → Sigmoid\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim: int, output_dim: int, num_hidden_layers: int, units: int):\n",
        "        super().__init__()\n",
        "        layers = [nn.Linear(input_dim, units), nn.LeakyReLU()]\n",
        "        for _ in range(num_hidden_layers):\n",
        "            layers += [nn.Linear(units, units), nn.LeakyReLU()]\n",
        "        layers += [nn.Linear(units, output_dim), nn.Sigmoid()]  # [0,1] 출력을 위해 sigmoid\n",
        "        self.net = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "NUM_LAYERS_OUTPUT = len(material_sequence)  # 출력 차원: 예) 3층 구조면 3\n",
        "inverse_net = InverseNet(NUM_WAVELENGTHS, NUM_LAYERS_OUTPUT, N_LAYERS, N_UNITS).to(device).to(torch.float64)\n",
        "optimizer = optim.Adam(inverse_net.parameters(), lr=LR)\n",
        "\n",
        "# ░░ 4. 학습 루프 시작 ░░\n",
        "print(\"\\n[INFO] Start training InverseNet (best params)\\n\")\n",
        "best_val_loss = float('inf')  # 초기 best loss (작을수록 좋음)\n",
        "\n",
        "for epoch in range(1, NUM_EPOCHS + 1):\n",
        "    # ---- (1) 학습 단계 ----\n",
        "    inverse_net.train()\n",
        "    epoch_loss = 0.0\n",
        "\n",
        "    for batch in train_loader:\n",
        "        T_target = batch['T_target'].to(device)       # 입력 스펙트럼 (정규화 상태)\n",
        "        d_norm_true = batch['d_norm'].to(device)      # 정답 두께 (정규화 상태)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        x = T_target.squeeze(1)                       # shape [B, 401] 보장\n",
        "        d_norm_pred = inverse_net(x)                  # 예측 두께 (정규화 상태)\n",
        "\n",
        "        # (a) 예측된 두께 → 복원 (nm)\n",
        "        d_nm_pred = destandardize_thickness(d_norm_pred)\n",
        "\n",
        "        # (b) forward TMM → 스펙트럼 예측\n",
        "        T_pred_batch = model(d_nm_pred)\n",
        "\n",
        "        # (c) 정답 스펙트럼 (정규화된 것) → 원래 스펙트럼으로 복원\n",
        "        T_target_destd = destandardize_spectrum(x)\n",
        "\n",
        "        # (d) Loss 계산\n",
        "        loss_spectrum = F.mse_loss(T_pred_batch, T_target_destd)\n",
        "        loss_thickness = F.mse_loss(d_norm_pred, d_norm_true.squeeze(1))\n",
        "        loss = loss_spectrum + ALPHA * loss_thickness if epoch <= BETA else loss_spectrum\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    # ---- (2) 검증 단계 ----\n",
        "    inverse_net.eval()\n",
        "    val_loss_total = 0.0\n",
        "    with torch.no_grad():\n",
        "        for val_batch in val_loader:\n",
        "            T_val = val_batch['T_target'].to(device)\n",
        "            d_norm_val = val_batch['d_norm'].to(device)\n",
        "\n",
        "            x_val = T_val.squeeze(1).to(torch.float64)\n",
        "            d_pred_val = inverse_net(x_val)\n",
        "\n",
        "            d_nm_val_pred = destandardize_thickness(d_pred_val)\n",
        "            T_val_pred = model(d_nm_val_pred)\n",
        "            T_val_destd = destandardize_spectrum(x_val)\n",
        "\n",
        "            loss_spectrum_v = F.mse_loss(T_val_pred, T_val_destd)\n",
        "            loss_thickness_v = F.mse_loss(d_pred_val, d_norm_val.squeeze(1))\n",
        "            val_loss = (loss_spectrum_v + ALPHA * loss_thickness_v) if epoch <= BETA else loss_spectrum_v\n",
        "            val_loss_total += val_loss.item()\n",
        "\n",
        "    # ---- (3) 로그 출력 & best model 저장 ----\n",
        "    avg_train_loss = epoch_loss / len(train_loader)\n",
        "    avg_val_loss = val_loss_total / len(val_loader)\n",
        "\n",
        "    if epoch % 1 == 0 or epoch == 1:\n",
        "        print(f\"Epoch[{epoch}/{NUM_EPOCHS}]  train: {avg_train_loss:.6f}  val: {avg_val_loss:.6f}\")\n",
        "\n",
        "    if avg_val_loss < best_val_loss:\n",
        "        best_val_loss = avg_val_loss\n",
        "        torch.save(inverse_net.state_dict(), SAVE_PATH)  # ⬅️ 가장 좋은 모델 저장\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAlTouN6Li4V"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ie-ly1QN0pFw"
      },
      "source": [
        "# **스펙트럼 저장 코드**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfUbpAta08jg"
      },
      "source": [
        "# **모델 불러오가**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-LujPwH0t6Y",
        "outputId": "7db0c0a3-d997-42b5-adfc-18074097f888"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 모델 파일 다운로드 성공\n",
            "✅ 모델 파라미터 로드 성공\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import urllib.request\n",
        "import os\n",
        "\n",
        "# ░░ 모델 정의 ░░\n",
        "class InverseNet(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, 768), nn.LeakyReLU(),\n",
        "            nn.Linear(768, 768), nn.LeakyReLU(),\n",
        "            nn.Linear(768, 768), nn.LeakyReLU(),\n",
        "            nn.Linear(768, 768), nn.LeakyReLU(),\n",
        "            nn.Linear(768, 768), nn.LeakyReLU(),\n",
        "            nn.Linear(768, output_dim), nn.Sigmoid()\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "# ░░ 모델 인스턴스 ░░\n",
        "inverse_net = InverseNet(input_dim=NUM_WAVELENGTHS, output_dim=len(material_sequence)).to(device).to(torch.float64)\n",
        "\n",
        "# ░░ GitHub에서 모델 다운로드 ░░\n",
        "github_url = \"https://raw.githubusercontent.com/KIMEUIJOON-KNU/Bi-directional/main/inverse_best_New.pth\"\n",
        "local_model_path = \"inverse_best_New.pth\"\n",
        "\n",
        "try:\n",
        "    urllib.request.urlretrieve(github_url, local_model_path)\n",
        "    print(\"✅ 모델 파일 다운로드 성공\")\n",
        "except Exception as e:\n",
        "    print(\"❌ 다운로드 실패:\", e)\n",
        "\n",
        "# ░░ 모델 파라미터 로드 ░░\n",
        "try:\n",
        "    inverse_net.load_state_dict(torch.load(local_model_path, map_location=device))\n",
        "    print(\"✅ 모델 파라미터 로드 성공\")\n",
        "except Exception as e:\n",
        "    print(\"❌ 모델 로드 실패:\", e)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import urllib.request\n",
        "import pandas as pd\n",
        "\n",
        "# ░░ (1) 모델 정의 (너가 만든 구조 그대로) ░░\n",
        "class InverseNet(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, 768), nn.LeakyReLU(),\n",
        "            nn.Linear(768, 768), nn.LeakyReLU(),\n",
        "            nn.Linear(768, 768), nn.LeakyReLU(),\n",
        "            nn.Linear(768, 768), nn.LeakyReLU(),\n",
        "            nn.Linear(768, 768), nn.LeakyReLU(),\n",
        "            nn.Linear(768, output_dim), nn.Sigmoid()\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "# ░░ (2) 모델 인스턴스 생성 ░░\n",
        "inverse_net = InverseNet(input_dim=NUM_WAVELENGTHS, output_dim=len(material_sequence)).to(device).to(torch.float64)\n",
        "\n",
        "# ░░ (3) GitHub에서 모델 파라미터 로드 ░░\n",
        "url = \"https://raw.githubusercontent.com/KIMEUIJOON-KNU/Bi-directional/main/inverse_best_New.pth\"\n",
        "save_path = \"inverse_best_New.pth\"\n",
        "urllib.request.urlretrieve(url, save_path)\n",
        "inverse_net.load_state_dict(torch.load(save_path, map_location=device))\n",
        "inverse_net.eval()\n",
        "print(\"✅ 모델 로드 완료 및 eval 모드 전환\")\n",
        "\n",
        "# ░░ (4) test set만 추출 ░░\n",
        "_, _, test_dataset = random_split(dataset, [train_size, val_size, test_size], generator=torch.Generator().manual_seed(42))\n",
        "\n",
        "# ░░ (5) 예측 실행 (전체 test set) ░░\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "all_true_d = []\n",
        "all_pred_d = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        T_test = batch['T_target'].to(device).squeeze(1)\n",
        "        d_true_norm = batch['d_norm'].to(device)\n",
        "\n",
        "        # 예측 (정규화된 두ㄴ께)\n",
        "        d_pred_norm = inverse_net(T_test)\n",
        "\n",
        "        # 정규화된 두께 → 실제 두께(nm)\n",
        "        d_pred_nm = destandardize_thickness(d_pred_norm).cpu().numpy()\n",
        "        d_true_nm = destandardize_thickness(d_true_norm).cpu().numpy()\n",
        "\n",
        "        all_true_d.append(d_true_nm)\n",
        "        all_pred_d.append(d_pred_nm)\n",
        "\n",
        "# ░░ (6) 결과 병합 및 DataFrame 출력 ░░\n",
        "true_all = torch.tensor(np.concatenate(all_true_d, axis=0))\n",
        "pred_all = torch.tensor(np.concatenate(all_pred_d, axis=0))\n",
        "\n",
        "df_result = pd.DataFrame({\n",
        "    \"True_d1\": true_all[:, 0],\n",
        "    \"True_d2\": true_all[:, 1],\n",
        "    \"True_d3\": true_all[:, 2],\n",
        "    \"Pred_d1\": pred_all[:, 0],\n",
        "    \"Pred_d2\": pred_all[:, 1],\n",
        "    \"Pred_d3\": pred_all[:, 2],\n",
        "})\n",
        "\n",
        "print(df_result.head(10))  # 상위 10개 결과 출력\n",
        "excel_path = \"inverse_test_result.xlsx\"\n",
        "df_result.to_excel(excel_path, index=False)\n",
        "print(f\"저장 완료: {excel_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3x6cGaVGb0O",
        "outputId": "e9ceeb78-1d58-439a-f7f0-6fa8a6dab000"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 모델 로드 완료 및 eval 모드 전환\n",
            "   True_d1  True_d2  True_d3    Pred_d1     Pred_d2    Pred_d3\n",
            "0     15.0    430.0     20.0  14.825414  429.895890  20.286923\n",
            "1     25.0    685.0     30.0  25.737539  684.942827  29.671310\n",
            "2     10.0    485.0      5.0   8.254471  486.948506   6.991958\n",
            "3     15.0    630.0     40.0  15.063486  630.098762  39.918744\n",
            "4     15.0    385.0     25.0  14.593657  384.706214  25.016640\n",
            "5     10.0    440.0     20.0   9.734059  439.415833  20.101497\n",
            "6     40.0    615.0     35.0  36.105777  615.054982  37.982515\n",
            "7     30.0    285.0      5.0   7.685507  294.291328  26.966713\n",
            "8     25.0    220.0     30.0  25.216201  219.926069  29.712750\n",
            "9     30.0    420.0     30.0  29.973181  419.944812  29.953681\n",
            "저장 완료: inverse_test_result.xlsx\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}